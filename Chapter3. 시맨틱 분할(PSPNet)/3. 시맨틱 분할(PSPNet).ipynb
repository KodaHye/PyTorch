{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "877ba1c0",
   "metadata": {},
   "source": [
    "## 3.1 시맨틱 분할이란"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b75fc8",
   "metadata": {},
   "source": [
    "#### 3.1.1 시맨틱 분할 개요\n",
    "* 시맨틱 분할\n",
    "    * 한 장의 이미지에 포함된 여러 영역과 이름을 픽섹 수준에서 지정하는 작업\n",
    "    * BBox가 아닌 픽셀 수준으로 어떠한 클래스 물체인지 라벨을 붙임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07559072",
   "metadata": {},
   "source": [
    "#### 3.1.2 시멘틱 분할 입출력\n",
    "* 시맨틱 분할의 입력\n",
    "    * 이미지\n",
    "* 시맨틱 분할의 출력\n",
    "    * 각 픽셀이 속한 클래스의 라벨 정보\n",
    "* 컬러 팔레트 형식\n",
    "    * 이미지 표현 기법\n",
    "    * 0부터 순서대로 각 숫자에 RGB를 대응시킨 컬러 팔레트를 준비하고 RGB 값 대응"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3d7fb8",
   "metadata": {},
   "source": [
    "#### 3.1.4 PSPNet을 활용한 물체 감지 흐름\n",
    "1. 전처리\n",
    "    * 이미지 resize(475X475)\n",
    "        * PSPNet에서는 임의의 크기로 resize했지만, 책에서는 475픽셀\n",
    "    * 색상 표준화\n",
    "2. PSPNet 신경망에 전처리한 화상 입력\n",
    "    * 출력: 21X475X475(클래스 수 높이, 폭)의 배열\n",
    "    * 출력 배열 값: 각 픽셀이 해당 클래스일 신뢰도(확률)에 대응\n",
    "3. PSPNet 출력 값에 픽셀별로 신뢰도가 가장 높은 클래스와 각 픽셀이 대응할 것으로 예상되는 클래스를 구함\n",
    "    * 시맨틱 분할의 출력: 픽셀별 신뢰도가 가장 높은 클래스 정보\n",
    "4. 시맨틱 분할의 출력을 원래 크기로 resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4cfa68",
   "metadata": {},
   "source": [
    "## 3.2 데이터셋과 데이터로더 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3a1ce6",
   "metadata": {},
   "source": [
    "#### 3.2.1 폴더 준비\n",
    "* `pspnet50_ADE20K.pth`: PSPNet 초기값으로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc24260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca2a547",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2917e24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = \"./weights/\"\n",
    "if not os.path.exists(weights_dir):\n",
    "    os.mkdir(weights_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c86eee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\"\n",
    "target_path = os.path.join(data_dir, \"VOCtrainval_11-May-2012.tar\") \n",
    "\n",
    "if not os.path.exists(target_path):\n",
    "    urllib.request.urlretrieve(url, target_path)\n",
    "    \n",
    "    tar = tarfile.TarFile(target_path)\n",
    "    tar.extractall(data_dir)  \n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0909d787",
   "metadata": {},
   "source": [
    "#### 3.2.2 화상 데이터 및 어노테이션 데이터 파일의 경로 리스트 작성\n",
    "* 시맨틱 분할 대상 파일의 정보\n",
    "    * `data/VOCdevkit/VOC2012/ImageSets/Segmentation/`\n",
    "    * `train.txt`, `val.txt`파일에 적혀있음\n",
    "* 어노테이션 데이터\n",
    "    * `data/VOCdevkit/VOC2012/SegmentationClass`에 저장된 `PNG`이미지 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146bf24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 import\n",
    "import torch\n",
    "import random\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9591e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수시드 설정\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf13ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datapath_list(rootpath):\n",
    "    \"\"\"\n",
    "    학습 및 검증용 이미지 데이터와 어노테이션 데이터의 파일 경로 리스트 작성\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rootpath : str\n",
    "        데이터 폴더 경로\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ret : train_img_list, train_anno_list, val_img_list, val_anno_list\n",
    "        데이터 경로를 저장한 리스트\n",
    "    \"\"\"\n",
    "\n",
    "    # 이미지 파일과 어노테이션 파일의 경로 템플릿 작성\n",
    "    imgpath_template = osp.join(rootpath, 'JPEGImages', '%s.jpg')\n",
    "    annopath_template = osp.join(rootpath, 'SegmentationClass', '%s.png')\n",
    "\n",
    "    # 훈련 및 검증 파일 각각 ID(파일 이름) 취득\n",
    "    train_id_names = osp.join(rootpath + 'ImageSets/Segmentation/train.txt')\n",
    "    val_id_names = osp.join(rootpath + 'ImageSets/Segmentation/val.txt')\n",
    "\n",
    "    # 훈련 데이터의 이미지 파일과 어노테이션 파일의 경로 리스트 작성\n",
    "    train_img_list = list()\n",
    "    train_anno_list = list()\n",
    "\n",
    "    for line in open(train_id_names):\n",
    "        file_id = line.strip()  # 공백과 줄 바꿈 제거\n",
    "        img_path = (imgpath_template % file_id)  # 이미지 경로\n",
    "        anno_path = (annopath_template % file_id)  # 어노테이션 경로\n",
    "        train_img_list.append(img_path)\n",
    "        train_anno_list.append(anno_path)\n",
    "\n",
    "    # 검증 데이터의 이미지 파일과 어노테이션 파일의 경로 리스트 작성\n",
    "    val_img_list = list()\n",
    "    val_anno_list = list()\n",
    "\n",
    "    for line in open(val_id_names):\n",
    "        file_id = line.strip()  # 공백과 줄 바꿈 제거\n",
    "        img_path = (imgpath_template % file_id)  # 이미지 경로\n",
    "        anno_path = (annopath_template % file_id)  # 어노테이션 경로\n",
    "        val_img_list.append(img_path)\n",
    "        val_anno_list.append(anno_path)\n",
    "\n",
    "    return train_img_list, train_anno_list, val_img_list, val_anno_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fcaf389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/VOCdevkit/VOC2012/JPEGImages\\2007_000032.jpg\n",
      "./data/VOCdevkit/VOC2012/SegmentationClass\\2007_000032.png\n"
     ]
    }
   ],
   "source": [
    "# 동작 확인: 파일 경로 리스트 취득\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n",
    "    rootpath=rootpath)\n",
    "\n",
    "print(train_img_list[0])\n",
    "print(train_anno_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1822d219",
   "metadata": {},
   "source": [
    "#### 3.2.3 데이터셋 작성\n",
    "* `DataTransform` 클래스\n",
    "    * `Dataset`클래스를 작성하기 전, 이미지와 어노테이션을 전처리하는 클래스\n",
    "    * `utils/data_augumentation.py` 사용\n",
    "    \n",
    "    * 화상 데이터와 어노테이션 데이터를 세트로 변환\n",
    "        * `Compose`클래스 내에서 변환\n",
    "    * 훈련 데이터 확장\n",
    "        * `Scale`\n",
    "        * `resize`\n",
    "        * `RandomRotation`\n",
    "            * -10도~10도 범위에서 화상 회전\n",
    "        * `RandomMirror`\n",
    "            * 1/2 확률로 좌우 반전\n",
    "        * `Normalize_Tensor`\n",
    "            * 화상 데이터를 파이토치 텐서 형식으로 변환 & 색상정보 표준화\n",
    "    * 검증 데이터\n",
    "        * 데이터 확장 실시 X\n",
    "        * 변환 및 색상 정보 표준화만 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8f2866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 처리 클래스와 데이터 확장 클래스 import\n",
    "from utils.data_augumentation import Compose, Scale, RandomRotation, RandomMirror, Resize, Normalize_Tensor\n",
    "\n",
    "\n",
    "class DataTransform():\n",
    "    \"\"\"\n",
    "    이미지와 어노테이션 전처리 클래스. 훈련 시와 검증 시 다르게 동작한다.\n",
    "    이미지 크기를 input_size X input_size로 한다.\n",
    "    훈련 시 데이터 확장을 수행한다.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    input_size : int\n",
    "        리사이즈 대상의 이미지 크기\n",
    "    color_mean : (R, G, B)\n",
    "        각 색상 채널의 평균값\n",
    "    color_std : (R, G, B)\n",
    "        각 색상 채널의 표준편자\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, color_mean, color_std):\n",
    "        self.data_transform = {\n",
    "            'train': Compose([\n",
    "                Scale(scale=[0.5, 1.5]),  # 이미지 확대\n",
    "                RandomRotation(angle=[-10, 10]),  # 회전\n",
    "                RandomMirror(),  # 랜덤미러\n",
    "                Resize(input_size),  # 리사이즈(input_size)\n",
    "                Normalize_Tensor(color_mean, color_std)  # 색상 정보의 표준화와 텐서화\n",
    "            ]),\n",
    "            'val': Compose([\n",
    "                Resize(input_size),  # 리사이즈(input_size)\n",
    "                Normalize_Tensor(color_mean, color_std)  # 색상 정보의 표준화와 텐서화\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    def __call__(self, phase, img, anno_class_img):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        phase : 'train' or 'val'\n",
    "            전처리 모드 지정\n",
    "        \"\"\"\n",
    "        return self.data_transform[phase](img, anno_class_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df425897",
   "metadata": {},
   "source": [
    "* Dataset 클래스\n",
    "    * `VOCDataset(train_img_list, train_anno_list, phase, transform)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86d4bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOCDataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    VOC2012의 Dataset을 만드는 클래스. 파이토치의 Dataset 클래스를 상속받는다.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    img_list : 리스트\n",
    "        이미지 경로를 저장한 리스트\n",
    "    anno_list : 리스트 \n",
    "        어노테이션 경로를 저장한 리스트\n",
    "    phase : 'train' or 'test'\n",
    "        학습 또는 훈련 설정\n",
    "    transform : object\n",
    "        전처리 클래스 인스턴스\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_list, anno_list, phase, transform):\n",
    "        self.img_list = img_list\n",
    "        self.anno_list = anno_list\n",
    "        self.phase = phase\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        '''이미지의 매수 반환'''\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        전처리한 이미지의 텐서 형식과 데이터 어노테이션 취득\n",
    "        '''\n",
    "        img, anno_class_img = self.pull_item(index)\n",
    "        return img, anno_class_img\n",
    "\n",
    "    def pull_item(self, index):\n",
    "        '''이미지의 텐서 형식 데이터와 어노테이션 취득'''\n",
    "\n",
    "        # 1. 이미지 읽기\n",
    "        image_file_path = self.img_list[index]\n",
    "        img = Image.open(image_file_path)   # [높이][폭][색RGB]\n",
    "\n",
    "        # 2. 어노테이션 이미지 읽기\n",
    "        anno_file_path = self.anno_list[index]\n",
    "        anno_class_img = Image.open(anno_file_path)   # [높이][폭]\n",
    "\n",
    "        # 3. 전처리 실시\n",
    "        img, anno_class_img = self.transform(self.phase, img, anno_class_img)\n",
    "\n",
    "        return img, anno_class_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1235e2",
   "metadata": {},
   "source": [
    "#### 데이터셋의 인스턴스가 만들어져 데이터를 꺼낼 수 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb95785f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 475, 475])\n",
      "torch.Size([475, 475])\n",
      "(tensor([[[ 1.6667,  1.5125,  1.5639,  ...,  1.7523,  1.6667,  1.7009],\n",
      "         [ 1.5810,  1.4269,  1.4783,  ...,  1.7009,  1.6153,  1.6495],\n",
      "         [ 1.5639,  1.4098,  1.4440,  ...,  1.6838,  1.5982,  1.6324],\n",
      "         ...,\n",
      "         [-0.4739, -0.4911, -0.5424,  ...,  1.2557,  1.1872,  1.2214],\n",
      "         [-0.5596, -0.4911, -0.4911,  ...,  1.2385,  1.1872,  1.2214],\n",
      "         [-0.6281, -0.3883, -0.3369,  ...,  1.2385,  1.1872,  1.2214]],\n",
      "\n",
      "        [[ 1.8333,  1.6758,  1.7283,  ...,  1.9209,  1.8333,  1.8683],\n",
      "         [ 1.7458,  1.5882,  1.6408,  ...,  1.8683,  1.7808,  1.8158],\n",
      "         [ 1.7283,  1.5707,  1.6057,  ...,  1.8508,  1.7633,  1.7983],\n",
      "         ...,\n",
      "         [-0.5826, -0.6001, -0.6527,  ...,  1.4132,  1.3431,  1.3431],\n",
      "         [-0.6702, -0.6001, -0.6001,  ...,  1.3957,  1.3431,  1.3431],\n",
      "         [-0.7402, -0.4951, -0.4426,  ...,  1.3957,  1.3431,  1.3431]],\n",
      "\n",
      "        [[ 2.0474,  1.8905,  1.9428,  ...,  2.1346,  2.0474,  2.0823],\n",
      "         [ 1.9603,  1.8034,  1.8557,  ...,  2.0823,  1.9951,  2.0300],\n",
      "         [ 1.9428,  1.7860,  1.8208,  ...,  2.0648,  1.9777,  2.0125],\n",
      "         ...,\n",
      "         [-0.6367, -0.6541, -0.7064,  ...,  1.6291,  1.5594,  1.5768],\n",
      "         [-0.7238, -0.6541, -0.6541,  ...,  1.6117,  1.5594,  1.5768],\n",
      "         [-0.7936, -0.5495, -0.4973,  ...,  1.6117,  1.5594,  1.5768]]]), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.uint8))\n"
     ]
    }
   ],
   "source": [
    "# 동작 확인\n",
    "# (RGB) 색의 평균치와 표준편차\n",
    "color_mean = (0.485, 0.456, 0.406)\n",
    "color_std = (0.229, 0.224, 0.225)\n",
    "\n",
    "# 데이터셋 작성\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(\n",
    "    input_size=475, color_mean=color_mean, color_std=color_std))\n",
    "\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(\n",
    "    input_size=475, color_mean=color_mean, color_std=color_std))\n",
    "\n",
    "# 데이터 추출 예\n",
    "print(val_dataset.__getitem__(0)[0].shape)\n",
    "print(val_dataset.__getitem__(0)[1].shape)\n",
    "print(val_dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1236e930",
   "metadata": {},
   "source": [
    "#### 3.2.4 데이터 로더 작성\n",
    "* 어노테이션 데이터 크기가 데이터마다 변하는 것이 아니기 때문에 <br>파이토치의 `DataLoader` 클래스 사용 가능!\n",
    "* 훈련 및 검증 데이터 각각 `DataLoader` 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80c7c94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 475, 475])\n",
      "torch.Size([8, 475, 475])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로더 작성\n",
    "batch_size = 8\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataloader = data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 사전 오브젝트로 정리\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "\n",
    "# 동작 확인\n",
    "batch_iterator = iter(dataloaders_dict[\"val\"])  # 반복자로 변환\n",
    "imges, anno_class_imges = next(batch_iterator)  # 첫 번째 요소를 꺼낸다.\n",
    "print(imges.size())  # torch.Size([8, 3, 475, 475])\n",
    "print(anno_class_imges.size())  # torch.Size([8, 3, 475, 475])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8087f17",
   "metadata": {},
   "source": [
    "## 3.3 PSPNet 네트워크 구성 및 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd822ef",
   "metadata": {},
   "source": [
    "#### 3.3.1 PSPNet\n",
    "* PSPNet 네트워크\n",
    "    * Feature(Encoder 모듈)\n",
    "        * 목적: 입력 이미지의 특징 파악\n",
    "        * 입력: 3⨉475⨉475\n",
    "        * 출력: 2048⨉60⨉60(ch⨉높이⨉폭)\n",
    "            * 화상 특징을 파악한 채널 2048개를 준비해야됨,,\n",
    "    * Pyramid Polling\n",
    "        * 픽셀의 물체 라벨을 구하기 위해서는 주변 정보 뿐만 아니라 더 넓은 범위의 화상 정보가 있어야 됨\n",
    "        * 네 가지 특징량 맵\n",
    "            * 이미지 전체를 차지하는 특징량\n",
    "            * 이미지의 1/2를 차지하는 특징량\n",
    "            * 이미지의 1/3을 차지하는 특징량\n",
    "            * 이미지의 1/6을 차지하는 특징량\n",
    "        * 출력: 4096⨉60⨉60\n",
    "    * Decoder(업샘플링 모듈)\n",
    "        * 목적\n",
    "            1. Pyramid Pooling 모듈의 출력을 21⨉60⨉60 텐서로 변환\n",
    "            2. 21⨉60⨉60 → 21⨉475⨉475(원래 이미지의 크기)\n",
    "        * 추론시\n",
    "            * Decoder 모듈의 출력으로 출력에 대한 최대 확률의 물체 클래스를 찾아 각 픽셀의 라벨을 결정\n",
    "    * AuxLoss\n",
    "        * Feature층 중간까지의 네트워크 파라미터 학습을 보조하는 역할(auxiliary)\n",
    "        * 네트워크 결합 파라미터의 학습을 수월하게 하기 위해 AuxLoss모듈 사용\n",
    "        * 손실함수 계산 보조\n",
    "        * Feature모듈로 중간 텐서를 뻐내 입력 데이터로 받음\n",
    "        * Feature 층 중간까지의 결과로 시맨틱 분할 실시\n",
    "        * 입력: 1024⨉60⨉60\n",
    "        * 출력: 21⨉475⨉475\n",
    "    \n",
    "   \n",
    "   * 신경망 학습\n",
    "       * AuxLoss모듈의 출력과 Decoder모듈의 출력을 모두 이미지의 어노테이션 데이터(정답정보)로 대응시켜 손실 값을 계산\n",
    "       * 손실 값 계산 후, 손살 값에 따른 오차 역전파 법을 실시하여 네트워크의 결합 파라미터 갱신\n",
    "       \n",
    "   * 추론\n",
    "        * Decoder 모듈의 출력만으로 시맨틱 분할 ~AuxLoss모듈 사용~\n",
    "<img src = \"../img/PSPNet module.PNG\" alt =\"PSPNet module image\" width = \"700px\" height =\"350px\" align = \"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cea7f8",
   "metadata": {},
   "source": [
    "#### 3.3.2 PSPPNet 클래스 구현\n",
    "* PSPNet\n",
    "    * 4개의 모듈이 있고 forward 메서드에서 순전파한다,,,\n",
    "* `forward`\n",
    "    * `PSPNet` 클래스의 메서드\n",
    "    * 순서대로 각 모듈의 서브 네트워크 실행\n",
    "    * 단, AuxLoss모듈을 Feature모듈의 featrue_dilated_res_1 뒤에 넣어 output_aux 변수로 출력을 작성\n",
    "    * `return (output, output_aux)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "942db238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "071fd882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(PSPNet, self).__init__()\n",
    "\n",
    "        # 파라미터 설정\n",
    "        block_config = [3, 4, 6, 3]  # resnet50\n",
    "        img_size = 475\n",
    "        img_size_8 = 60  # img_size의 1/8로 설정\n",
    "\n",
    "        # 네 개의 모듈을 구성하는 서브 네트워크 준비\n",
    "        self.feature_conv = FeatureMap_convolution()\n",
    "        self.feature_res_1 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[0], in_channels=128, mid_channels=64, out_channels=256, stride=1, dilation=1)\n",
    "        self.feature_res_2 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[1], in_channels=256, mid_channels=128, out_channels=512, stride=2, dilation=1)\n",
    "        self.feature_dilated_res_1 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[2], in_channels=512, mid_channels=256, out_channels=1024, stride=1, dilation=2)\n",
    "        self.feature_dilated_res_2 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[3], in_channels=1024, mid_channels=512, out_channels=2048, stride=1, dilation=4)\n",
    "\n",
    "        self.pyramid_pooling = PyramidPooling(in_channels=2048, pool_sizes=[\n",
    "            6, 3, 2, 1], height=img_size_8, width=img_size_8)\n",
    "\n",
    "        self.decode_feature = DecodePSPFeature(\n",
    "            height=img_size, width=img_size, n_classes=n_classes)\n",
    "\n",
    "        self.aux = AuxiliaryPSPlayers(\n",
    "            in_channels=1024, height=img_size, width=img_size, n_classes=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_conv(x)\n",
    "        x = self.feature_res_1(x)\n",
    "        x = self.feature_res_2(x)\n",
    "        x = self.feature_dilated_res_1(x)\n",
    "\n",
    "        output_aux = self.aux(x)  # Feature 모듈의 중간을 Aux 모듈로\n",
    "\n",
    "        x = self.feature_dilated_res_2(x)\n",
    "\n",
    "        x = self.pyramid_pooling(x)\n",
    "        output = self.decode_feature(x)\n",
    "\n",
    "        return (output, output_aux)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac88d709",
   "metadata": {},
   "source": [
    "## 3.4 Feature 모듈 설명 및 구현(ResNet)\n",
    "* Feature 모듈\n",
    "    * 다섯 개의 서브 네트워크로 구성\n",
    "        * FeatureMap_convolution\n",
    "        * resodialBlockPSP\n",
    "        * residualBlockPSP\n",
    "        * residualBlockPSP(dilated)\n",
    "            * 출력 텐서가 AuxLoss로,,,\n",
    "            * AuxLoss 모듈에서 출력텐서로 픽셀별 클래스를 분류하고, <br>손실 값을 Feature모듈의 전반부 네 개의 서브 네트워크를 학습하는데 사용\n",
    "        * residualBlockPSP(dilated)\n",
    "* `FeatureMap_convolution`\n",
    "* `ResidualBlockPSP`\n",
    "* `dilation`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8db4e4",
   "metadata": {},
   "source": [
    "#### 3.4.2 서브 네트워크 FeatureMap_convolution\n",
    "* FeatureMap_convolution모듈의 첫 번째 서브 네트워크\n",
    "* 입력\n",
    "    * 전처리된 이미지(3⨉475⨉475)\n",
    "* 출력\n",
    "    * 128⨉119⨉119\n",
    "* 네 가지 요소로 구성\n",
    "    * conv2dBatchNormRelu\n",
    "        * 합성곱 층\n",
    "        * 배치 정규화\n",
    "        * Relu\n",
    "    * 최대 풀링 층\n",
    "* 단순히 합성곱, 배치 정규화, 최대 풀링으로 **이미지의 특징량을 추출**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18bf703",
   "metadata": {},
   "source": [
    "#### 3.4.3 FeatureMap_convolution 구현\n",
    "* `conv2dBatchNormRelu`\n",
    "    * 합성곱 층, 배치 정규화, ReLU를 세트\n",
    "    * 내부에서 사용하는 합성곱 층의 인수 지정\n",
    "    * `Relu(inplace = True)`\n",
    "        * 메모리 절약\n",
    "* `FeatureMap_convolution`\n",
    "    * `conv2dBatchNormRelu` 사용\n",
    "    * `conv2dBatchNormrelu` 3개, 최대 풀링 층 1개\n",
    "        * `forward`: 4개의 층을 순전파하는 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da5b01ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNormRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
    "        super(conv2DBatchNormRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, dilation, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # inplase 설정으로 입력을 저장하지 않고 출력을 계산하여 메모리 절역\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        outputs = self.relu(x)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21a1bdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMap_convolution(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''구성할 네트워크 준비'''\n",
    "        super(FeatureMap_convolution, self).__init__()\n",
    "\n",
    "        # 합성곱 층 1\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 3, 64, 3, 2, 1, 1, False\n",
    "        self.cbnr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        # 합성곱 층 2\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 64, 3, 1, 1, 1, False\n",
    "        self.cbnr_2 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        # 합성곱 층 3\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 128, 3, 1, 1, 1, False\n",
    "        self.cbnr_3 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        # 최대 풀링 층\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbnr_1(x)\n",
    "        x = self.cbnr_2(x)\n",
    "        x = self.cbnr_3(x)\n",
    "        outputs = self.maxpool(x)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647d4345",
   "metadata": {},
   "source": [
    "#### 3.4.4 ResidualBlockPSP\n",
    "* ResidualNetwork(ResNet) 신경망에서 사용되는 ResidualBlock구조 사용\n",
    "* `bottleNeckPSP`클래스를 지나 `bottleNeckIdentifyPSP`클래스를 여러 번 반복하여 출력\n",
    "    * 4개의 `ResidualBlockPSP`서브 네트워크를 지날 때, `bottleNeckIdentifyPSP` 클래스의 반복 횟수: 3, 4, 6, 3\n",
    "\n",
    "#### RedisualBLockPSP 구현\n",
    "* 생성자\n",
    "    * `bottelNeckPSP`(1)\n",
    "    * `bottleNeckIdentifyPSP`(여러개)\n",
    "* `nn.Sequential`\n",
    "    * 생성자에서 준비한 네트워크 클래스의 순전파를 자동실행하는 함수(forward)가 자동실행\n",
    "    * forward함수를 정의하지 않아도 됨\n",
    "        * `ReatureMap_convolution`구현에서는 `nn.Module`을 상속했기 때문에 forward함수가 필요함!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b12d98",
   "metadata": {},
   "source": [
    "#### 3.4.5 bottleNeckPSP와 bottleNeckIdentifyPSP\n",
    "* 입력이 두 갈래로 나뉘어 처리\n",
    "    * 스킵 결합(bypass): 두 갈래로 나누어진 입력 아래쪽 루트\n",
    "    * `ResidualBlock`\n",
    "        * 스킵결합을 사용하는 서브 네트워크\n",
    "        * 스킵결합으로 서브 네트워크 입력을 거의 그대로 결합 ,,\n",
    "* `bottleNeckPSP`와 `bottleNeckIdentifyPSP`의 차이점\n",
    "    * 스킵결합에서 합성곱 층의 유무\n",
    "    * `bottleNeckPSP`: 스킵결합에 합성곱 층 한 번 적용\n",
    "    * `bottleNeckIdentify`: 합성곱 층 적용 X\n",
    "* `bottleNeckPSP`\n",
    "* `bottleNeckIdentifyPSP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00922326",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockPSP(nn.Sequential):\n",
    "    def __init__(self, n_blocks, in_channels, mid_channels, out_channels, stride, dilation):\n",
    "        super(ResidualBlockPSP, self).__init__()\n",
    "\n",
    "        # bottleNeckPSP 준비\n",
    "        self.add_module(\n",
    "            \"block1\",\n",
    "            bottleNeckPSP(in_channels, mid_channels,\n",
    "                          out_channels, stride, dilation)\n",
    "        )\n",
    "\n",
    "        # bottleNeckIdentifyPSP 반복 준비\n",
    "        for i in range(n_blocks - 1):\n",
    "            self.add_module(\n",
    "                \"block\" + str(i+2),\n",
    "                bottleNeckIdentifyPSP(\n",
    "                    out_channels, mid_channels, stride, dilation)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a508507",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNorm(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
    "        super(conv2DBatchNorm, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, dilation, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        outputs = self.batchnorm(x)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32326294",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleNeckPSP(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride, dilation):\n",
    "        super(bottleNeckPSP, self).__init__()\n",
    "\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            mid_channels, mid_channels, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False)\n",
    "        self.cb_3 = conv2DBatchNorm(\n",
    "            mid_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        # 스킵 결합\n",
    "        self.cb_residual = conv2DBatchNorm(\n",
    "            in_channels, out_channels, kernel_size=1, stride=stride, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual = self.cb_residual(x)\n",
    "        return self.relu(conv + residual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfde984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleNeckIdentifyPSP(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, stride, dilation):\n",
    "        super(bottleNeckIdentifyPSP, self).__init__()\n",
    "\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            mid_channels, mid_channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=False)\n",
    "        self.cb_3 = conv2DBatchNorm(\n",
    "            mid_channels, in_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual = x\n",
    "        return self.relu(conv + residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f205a",
   "metadata": {},
   "source": [
    "## 3.5 Pyramid Pooling 모듈 설명 및 구현\n",
    "* `PyramidPooling` 클래스로 이루어진 하나의 서브 네트워크로 구성\n",
    "* 입력\n",
    "    * 2048⨉60⨉60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "304a93f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyramidPooling(nn.Module):\n",
    "    def __init__(self, in_channels, pool_sizes, height, width):\n",
    "        super(PyramidPooling, self).__init__()\n",
    "\n",
    "        # forward에서 사용하는 이미지 크기\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        # 각 합성곱 층의 출력 채널 수\n",
    "        out_channels = int(in_channels / len(pool_sizes))\n",
    "\n",
    "        # 각 합성곱 층 작성\n",
    "        # 다음은 for문으로 구현하는 것이 좋지만 이해를 돕기 위해 상세하게 작성한다.\n",
    "        # pool_sizes: [6, 3, 2, 1]\n",
    "        self.avpool_1 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[0])\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_2 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[1])\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_3 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[2])\n",
    "        self.cbr_3 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_4 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[3])\n",
    "        self.cbr_4 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.cbr_1(self.avpool_1(x))\n",
    "        out1 = F.interpolate(out1, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out2 = self.cbr_2(self.avpool_2(x))\n",
    "        out2 = F.interpolate(out2, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out3 = self.cbr_3(self.avpool_3(x))\n",
    "        out3 = F.interpolate(out3, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out4 = self.cbr_4(self.avpool_4(x))\n",
    "        out4 = F.interpolate(out4, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        # 최종 결합시킬 dim = 1으로 채널 수 차원에서 결합\n",
    "        output = torch.cat([x, out1, out2, out3, out4], dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66d36964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodePSPFeature(nn.Module):\n",
    "    def __init__(self, height, width, n_classes):\n",
    "        super(DecodePSPFeature, self).__init__()\n",
    "\n",
    "        # forward에 사용하는 이미지 크기\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        self.cbr = conv2DBatchNormRelu(\n",
    "            in_channels=4096, out_channels=512, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        self.classification = nn.Conv2d(\n",
    "            in_channels=512, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbr(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classification(x)\n",
    "        output = F.interpolate(\n",
    "            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b33bf0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxiliaryPSPlayers(nn.Module):\n",
    "    def __init__(self, in_channels, height, width, n_classes):\n",
    "        super(AuxiliaryPSPlayers, self).__init__()\n",
    "\n",
    "        # forward에 사용하는 화상 크기\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        self.cbr = conv2DBatchNormRelu(\n",
    "            in_channels=in_channels, out_channels=256, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        self.classification = nn.Conv2d(\n",
    "            in_channels=256, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbr(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classification(x)\n",
    "        output = F.interpolate(\n",
    "            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48339644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PSPNet(\n",
       "  (feature_conv): FeatureMap_convolution(\n",
       "    (cbnr_1): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (cbnr_2): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (cbnr_3): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (feature_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (feature_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block5): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block6): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (pyramid_pooling): PyramidPooling(\n",
       "    (avpool_1): AdaptiveAvgPool2d(output_size=6)\n",
       "    (cbr_1): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (avpool_2): AdaptiveAvgPool2d(output_size=3)\n",
       "    (cbr_2): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (avpool_3): AdaptiveAvgPool2d(output_size=2)\n",
       "    (cbr_3): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (avpool_4): AdaptiveAvgPool2d(output_size=1)\n",
       "    (cbr_4): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (decode_feature): DecodePSPFeature(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1)\n",
       "    (classification): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux): AuxiliaryPSPlayers(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1)\n",
       "    (classification): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 정의\n",
    "net = PSPNet(n_classes=21)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a0d97f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[-8.4430e-03, -4.2839e-02, -7.7234e-02,  ..., -2.9316e-01,\n",
      "           -3.3205e-01, -3.7093e-01],\n",
      "          [ 2.2137e-02, -1.1379e-02, -4.4895e-02,  ..., -2.8819e-01,\n",
      "           -3.2154e-01, -3.5490e-01],\n",
      "          [ 5.2717e-02,  2.0081e-02, -1.2556e-02,  ..., -2.8321e-01,\n",
      "           -3.1104e-01, -3.3887e-01],\n",
      "          ...,\n",
      "          [-3.6519e-02, -3.7442e-02, -3.8365e-02,  ...,  1.0266e-01,\n",
      "            1.1877e-01,  1.3487e-01],\n",
      "          [-3.4343e-02, -3.4584e-02, -3.4825e-02,  ...,  9.2854e-02,\n",
      "            1.0968e-01,  1.2650e-01],\n",
      "          [-3.2168e-02, -3.1726e-02, -3.1285e-02,  ...,  8.3047e-02,\n",
      "            1.0059e-01,  1.1814e-01]],\n",
      "\n",
      "         [[-3.5119e-01, -3.3616e-01, -3.2113e-01,  ..., -3.2207e-01,\n",
      "           -3.2985e-01, -3.3763e-01],\n",
      "          [-3.6116e-01, -3.4460e-01, -3.2804e-01,  ..., -2.9533e-01,\n",
      "           -3.0126e-01, -3.0718e-01],\n",
      "          [-3.7114e-01, -3.5305e-01, -3.3496e-01,  ..., -2.6859e-01,\n",
      "           -2.7266e-01, -2.7674e-01],\n",
      "          ...,\n",
      "          [-4.3947e-01, -4.4546e-01, -4.5146e-01,  ..., -2.6929e-01,\n",
      "           -2.7204e-01, -2.7478e-01],\n",
      "          [-4.9126e-01, -4.9621e-01, -5.0115e-01,  ..., -2.6798e-01,\n",
      "           -2.6802e-01, -2.6806e-01],\n",
      "          [-5.4306e-01, -5.4695e-01, -5.5084e-01,  ..., -2.6667e-01,\n",
      "           -2.6401e-01, -2.6134e-01]],\n",
      "\n",
      "         [[ 1.2269e-01,  1.7563e-01,  2.2857e-01,  ...,  4.0701e-01,\n",
      "            3.9654e-01,  3.8608e-01],\n",
      "          [ 1.5252e-01,  1.9448e-01,  2.3645e-01,  ...,  4.1115e-01,\n",
      "            4.0346e-01,  3.9578e-01],\n",
      "          [ 1.8235e-01,  2.1334e-01,  2.4433e-01,  ...,  4.1528e-01,\n",
      "            4.1038e-01,  4.0548e-01],\n",
      "          ...,\n",
      "          [ 1.3218e-01,  9.5191e-02,  5.8203e-02,  ..., -1.7026e-02,\n",
      "            1.4445e-03,  1.9915e-02],\n",
      "          [ 1.0078e-01,  6.0776e-02,  2.0775e-02,  ..., -9.2235e-02,\n",
      "           -7.3108e-02, -5.3980e-02],\n",
      "          [ 6.9373e-02,  2.6360e-02, -1.6653e-02,  ..., -1.6744e-01,\n",
      "           -1.4766e-01, -1.2787e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.8553e-02,  6.9665e-03, -2.4620e-02,  ...,  2.0286e-01,\n",
      "            2.2313e-01,  2.4340e-01],\n",
      "          [ 3.2146e-02,  4.6777e-03, -2.2790e-02,  ...,  1.9347e-01,\n",
      "            2.1385e-01,  2.3422e-01],\n",
      "          [ 2.5738e-02,  2.3889e-03, -2.0960e-02,  ...,  1.8409e-01,\n",
      "            2.0457e-01,  2.2504e-01],\n",
      "          ...,\n",
      "          [ 2.5595e-01,  2.5705e-01,  2.5815e-01,  ...,  1.3951e-01,\n",
      "            1.3014e-01,  1.2076e-01],\n",
      "          [ 2.7676e-01,  2.7750e-01,  2.7825e-01,  ...,  1.5418e-01,\n",
      "            1.4247e-01,  1.3076e-01],\n",
      "          [ 2.9756e-01,  2.9796e-01,  2.9835e-01,  ...,  1.6884e-01,\n",
      "            1.5480e-01,  1.4075e-01]],\n",
      "\n",
      "         [[-1.2417e-01, -1.3881e-01, -1.5344e-01,  ..., -2.9976e-01,\n",
      "           -2.9331e-01, -2.8686e-01],\n",
      "          [-1.0254e-01, -1.2173e-01, -1.4092e-01,  ..., -3.0460e-01,\n",
      "           -2.9775e-01, -2.9091e-01],\n",
      "          [-8.0912e-02, -1.0465e-01, -1.2840e-01,  ..., -3.0944e-01,\n",
      "           -3.0219e-01, -2.9495e-01],\n",
      "          ...,\n",
      "          [-7.7678e-02, -8.6400e-02, -9.5123e-02,  ..., -2.1701e-01,\n",
      "           -2.2796e-01, -2.3891e-01],\n",
      "          [-7.0867e-02, -7.8330e-02, -8.5794e-02,  ..., -2.0570e-01,\n",
      "           -2.1523e-01, -2.2475e-01],\n",
      "          [-6.4055e-02, -7.0260e-02, -7.6465e-02,  ..., -1.9439e-01,\n",
      "           -2.0249e-01, -2.1059e-01]],\n",
      "\n",
      "         [[-1.7892e-01, -1.4408e-01, -1.0924e-01,  ...,  1.3228e-01,\n",
      "            1.2009e-01,  1.0790e-01],\n",
      "          [-1.8074e-01, -1.4811e-01, -1.1549e-01,  ...,  1.3030e-01,\n",
      "            1.2404e-01,  1.1779e-01],\n",
      "          [-1.8257e-01, -1.5215e-01, -1.2174e-01,  ...,  1.2832e-01,\n",
      "            1.2800e-01,  1.2768e-01],\n",
      "          ...,\n",
      "          [-1.9236e-01, -1.5144e-01, -1.1052e-01,  ..., -1.6600e-01,\n",
      "           -1.7473e-01, -1.8345e-01],\n",
      "          [-2.0841e-01, -1.6621e-01, -1.2402e-01,  ..., -1.8870e-01,\n",
      "           -1.9783e-01, -2.0696e-01],\n",
      "          [-2.2446e-01, -1.8098e-01, -1.3751e-01,  ..., -2.1140e-01,\n",
      "           -2.2094e-01, -2.3047e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.0088e-02, -6.0602e-02, -5.1115e-02,  ..., -1.8576e-01,\n",
      "           -1.5766e-01, -1.2955e-01],\n",
      "          [-4.9535e-02, -4.4475e-02, -3.9416e-02,  ..., -2.0119e-01,\n",
      "           -1.7858e-01, -1.5598e-01],\n",
      "          [-2.8982e-02, -2.8349e-02, -2.7717e-02,  ..., -2.1661e-01,\n",
      "           -1.9951e-01, -1.8241e-01],\n",
      "          ...,\n",
      "          [ 6.6939e-02,  5.5284e-02,  4.3629e-02,  ..., -6.5876e-02,\n",
      "           -9.7125e-02, -1.2837e-01],\n",
      "          [ 6.6133e-02,  5.4396e-02,  4.2658e-02,  ..., -4.3605e-02,\n",
      "           -8.0547e-02, -1.1749e-01],\n",
      "          [ 6.5327e-02,  5.3507e-02,  4.1687e-02,  ..., -2.1333e-02,\n",
      "           -6.3970e-02, -1.0661e-01]],\n",
      "\n",
      "         [[-7.9504e-02, -7.9436e-02, -7.9367e-02,  ..., -2.6312e-01,\n",
      "           -2.5929e-01, -2.5546e-01],\n",
      "          [-4.7213e-02, -5.4984e-02, -6.2754e-02,  ..., -2.3669e-01,\n",
      "           -2.3185e-01, -2.2701e-01],\n",
      "          [-1.4922e-02, -3.0532e-02, -4.6141e-02,  ..., -2.1026e-01,\n",
      "           -2.0441e-01, -1.9856e-01],\n",
      "          ...,\n",
      "          [-1.5983e-01, -1.4586e-01, -1.3189e-01,  ..., -4.1451e-01,\n",
      "           -4.1366e-01, -4.1281e-01],\n",
      "          [-1.3941e-01, -1.2994e-01, -1.2048e-01,  ..., -4.4289e-01,\n",
      "           -4.3560e-01, -4.2830e-01],\n",
      "          [-1.1899e-01, -1.1402e-01, -1.0906e-01,  ..., -4.7128e-01,\n",
      "           -4.5753e-01, -4.4378e-01]],\n",
      "\n",
      "         [[ 2.8650e-01,  3.1120e-01,  3.3590e-01,  ...,  5.3410e-01,\n",
      "            4.9641e-01,  4.5871e-01],\n",
      "          [ 2.5189e-01,  2.7661e-01,  3.0134e-01,  ...,  5.3210e-01,\n",
      "            5.0111e-01,  4.7011e-01],\n",
      "          [ 2.1728e-01,  2.4203e-01,  2.6678e-01,  ...,  5.3010e-01,\n",
      "            5.0581e-01,  4.8152e-01],\n",
      "          ...,\n",
      "          [ 1.0058e-01,  9.4546e-02,  8.8508e-02,  ..., -3.7538e-02,\n",
      "           -2.5451e-02, -1.3364e-02],\n",
      "          [ 7.3495e-02,  6.2612e-02,  5.1730e-02,  ..., -8.6836e-02,\n",
      "           -6.8060e-02, -4.9284e-02],\n",
      "          [ 4.6406e-02,  3.0679e-02,  1.4951e-02,  ..., -1.3613e-01,\n",
      "           -1.1067e-01, -8.5204e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9560e-02, -5.4568e-02, -7.9576e-02,  ...,  1.7456e-01,\n",
      "            1.8942e-01,  2.0428e-01],\n",
      "          [-2.5508e-03, -2.7186e-02, -5.1822e-02,  ...,  1.5796e-01,\n",
      "            1.7548e-01,  1.9300e-01],\n",
      "          [ 2.4459e-02,  1.9579e-04, -2.4067e-02,  ...,  1.4137e-01,\n",
      "            1.6155e-01,  1.8172e-01],\n",
      "          ...,\n",
      "          [ 3.3795e-01,  3.2195e-01,  3.0596e-01,  ...,  1.5878e-01,\n",
      "            1.3896e-01,  1.1914e-01],\n",
      "          [ 3.6275e-01,  3.4681e-01,  3.3086e-01,  ...,  1.5364e-01,\n",
      "            1.2914e-01,  1.0463e-01],\n",
      "          [ 3.8756e-01,  3.7166e-01,  3.5576e-01,  ...,  1.4851e-01,\n",
      "            1.1932e-01,  9.0125e-02]],\n",
      "\n",
      "         [[-1.3657e-01, -1.3046e-01, -1.2436e-01,  ..., -3.9198e-01,\n",
      "           -4.0262e-01, -4.1326e-01],\n",
      "          [-1.2967e-01, -1.2593e-01, -1.2219e-01,  ..., -3.8596e-01,\n",
      "           -3.9660e-01, -4.0724e-01],\n",
      "          [-1.2278e-01, -1.2140e-01, -1.2002e-01,  ..., -3.7994e-01,\n",
      "           -3.9058e-01, -4.0122e-01],\n",
      "          ...,\n",
      "          [ 1.5883e-01,  1.4176e-01,  1.2469e-01,  ..., -2.4570e-01,\n",
      "           -2.5155e-01, -2.5739e-01],\n",
      "          [ 1.9238e-01,  1.7416e-01,  1.5593e-01,  ..., -2.4114e-01,\n",
      "           -2.4905e-01, -2.5695e-01],\n",
      "          [ 2.2593e-01,  2.0656e-01,  1.8718e-01,  ..., -2.3658e-01,\n",
      "           -2.4654e-01, -2.5651e-01]],\n",
      "\n",
      "         [[-1.0617e-01, -8.6498e-02, -6.6829e-02,  ...,  6.5304e-02,\n",
      "            8.1902e-02,  9.8501e-02],\n",
      "          [-8.7798e-02, -7.8229e-02, -6.8661e-02,  ...,  5.8600e-02,\n",
      "            7.4712e-02,  9.0824e-02],\n",
      "          [-6.9428e-02, -6.9961e-02, -7.0493e-02,  ...,  5.1896e-02,\n",
      "            6.7522e-02,  8.3147e-02],\n",
      "          ...,\n",
      "          [ 1.5875e-02,  2.1383e-02,  2.6892e-02,  ...,  1.2392e-01,\n",
      "            1.1882e-01,  1.1372e-01],\n",
      "          [ 2.4517e-02,  3.0619e-02,  3.6721e-02,  ...,  1.3805e-01,\n",
      "            1.3282e-01,  1.2759e-01],\n",
      "          [ 3.3159e-02,  3.9854e-02,  4.6549e-02,  ...,  1.5219e-01,\n",
      "            1.4683e-01,  1.4147e-01]]]], grad_fn=<UpsampleBilinear2DBackward>), tensor([[[[ 0.2490,  0.2546,  0.2601,  ...,  0.1034,  0.0818,  0.0601],\n",
      "          [ 0.2325,  0.2304,  0.2283,  ...,  0.1018,  0.0793,  0.0569],\n",
      "          [ 0.2160,  0.2062,  0.1964,  ...,  0.1001,  0.0769,  0.0537],\n",
      "          ...,\n",
      "          [ 0.0454,  0.0482,  0.0510,  ...,  0.0343,  0.0343,  0.0344],\n",
      "          [ 0.0393,  0.0418,  0.0442,  ...,  0.0296,  0.0315,  0.0334],\n",
      "          [ 0.0331,  0.0353,  0.0375,  ...,  0.0249,  0.0287,  0.0324]],\n",
      "\n",
      "         [[ 0.5297,  0.5178,  0.5059,  ...,  0.4881,  0.4553,  0.4226],\n",
      "          [ 0.5207,  0.5060,  0.4913,  ...,  0.4651,  0.4378,  0.4106],\n",
      "          [ 0.5116,  0.4942,  0.4767,  ...,  0.4421,  0.4203,  0.3986],\n",
      "          ...,\n",
      "          [ 0.3711,  0.3641,  0.3571,  ...,  0.3611,  0.3277,  0.2943],\n",
      "          [ 0.3822,  0.3754,  0.3687,  ...,  0.3818,  0.3414,  0.3011],\n",
      "          [ 0.3934,  0.3868,  0.3803,  ...,  0.4025,  0.3552,  0.3079]],\n",
      "\n",
      "         [[ 0.0944,  0.0564,  0.0184,  ..., -0.0014, -0.0043, -0.0072],\n",
      "          [ 0.0555,  0.0246, -0.0063,  ...,  0.0023,  0.0048,  0.0073],\n",
      "          [ 0.0167, -0.0072, -0.0311,  ...,  0.0060,  0.0139,  0.0218],\n",
      "          ...,\n",
      "          [-0.1239, -0.1361, -0.1483,  ...,  0.2034,  0.2552,  0.3071],\n",
      "          [-0.1587, -0.1658, -0.1729,  ...,  0.2179,  0.2694,  0.3209],\n",
      "          [-0.1936, -0.1956, -0.1976,  ...,  0.2325,  0.2835,  0.3346]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0848, -0.0785, -0.0721,  ..., -0.0908, -0.0753, -0.0598],\n",
      "          [-0.1047, -0.0991, -0.0935,  ..., -0.0766, -0.0656, -0.0546],\n",
      "          [-0.1247, -0.1198, -0.1150,  ..., -0.0623, -0.0559, -0.0494],\n",
      "          ...,\n",
      "          [-0.2562, -0.2306, -0.2051,  ..., -0.1421, -0.1155, -0.0888],\n",
      "          [-0.2338, -0.2123, -0.1907,  ..., -0.1664, -0.1435, -0.1206],\n",
      "          [-0.2114, -0.1939, -0.1764,  ..., -0.1907, -0.1715, -0.1523]],\n",
      "\n",
      "         [[ 0.2006,  0.1820,  0.1634,  ...,  0.0766,  0.0574,  0.0382],\n",
      "          [ 0.1934,  0.1749,  0.1564,  ...,  0.0834,  0.0687,  0.0539],\n",
      "          [ 0.1861,  0.1678,  0.1495,  ...,  0.0901,  0.0799,  0.0697],\n",
      "          ...,\n",
      "          [ 0.0971,  0.1090,  0.1208,  ...,  0.1545,  0.1655,  0.1765],\n",
      "          [ 0.0724,  0.0906,  0.1087,  ...,  0.1565,  0.1748,  0.1930],\n",
      "          [ 0.0477,  0.0721,  0.0966,  ...,  0.1585,  0.1840,  0.2095]],\n",
      "\n",
      "         [[-0.1260, -0.1218, -0.1176,  ...,  0.0230,  0.0396,  0.0562],\n",
      "          [-0.1405, -0.1316, -0.1228,  ...,  0.0397,  0.0532,  0.0668],\n",
      "          [-0.1550, -0.1414, -0.1279,  ...,  0.0563,  0.0669,  0.0774],\n",
      "          ...,\n",
      "          [-0.0721, -0.0855, -0.0989,  ..., -0.1600, -0.1393, -0.1187],\n",
      "          [-0.0655, -0.0789, -0.0923,  ..., -0.1587, -0.1334, -0.1081],\n",
      "          [-0.0590, -0.0723, -0.0856,  ..., -0.1574, -0.1275, -0.0976]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1330,  0.1434,  0.1538,  ...,  0.1431,  0.1088,  0.0745],\n",
      "          [ 0.1128,  0.1244,  0.1361,  ...,  0.1219,  0.0877,  0.0534],\n",
      "          [ 0.0926,  0.1054,  0.1183,  ...,  0.1008,  0.0666,  0.0323],\n",
      "          ...,\n",
      "          [ 0.2772,  0.2488,  0.2203,  ...,  0.1825,  0.1686,  0.1547],\n",
      "          [ 0.2903,  0.2534,  0.2165,  ...,  0.1885,  0.1766,  0.1647],\n",
      "          [ 0.3034,  0.2581,  0.2128,  ...,  0.1946,  0.1847,  0.1748]],\n",
      "\n",
      "         [[ 0.5022,  0.5016,  0.5011,  ...,  0.4237,  0.4420,  0.4603],\n",
      "          [ 0.4711,  0.4722,  0.4733,  ...,  0.4158,  0.4308,  0.4457],\n",
      "          [ 0.4400,  0.4428,  0.4456,  ...,  0.4079,  0.4195,  0.4312],\n",
      "          ...,\n",
      "          [ 0.5714,  0.5365,  0.5016,  ...,  0.4110,  0.4173,  0.4236],\n",
      "          [ 0.5724,  0.5370,  0.5016,  ...,  0.4319,  0.4321,  0.4323],\n",
      "          [ 0.5734,  0.5375,  0.5017,  ...,  0.4529,  0.4470,  0.4411]],\n",
      "\n",
      "         [[ 0.0714,  0.0438,  0.0161,  ...,  0.0446,  0.0506,  0.0565],\n",
      "          [ 0.0691,  0.0394,  0.0097,  ...,  0.0299,  0.0413,  0.0526],\n",
      "          [ 0.0668,  0.0350,  0.0033,  ...,  0.0151,  0.0320,  0.0488],\n",
      "          ...,\n",
      "          [-0.2096, -0.2101, -0.2107,  ..., -0.0504, -0.0399, -0.0294],\n",
      "          [-0.2377, -0.2399, -0.2422,  ..., -0.0484, -0.0388, -0.0293],\n",
      "          [-0.2658, -0.2698, -0.2737,  ..., -0.0463, -0.0378, -0.0293]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3477, -0.3236, -0.2996,  ..., -0.2748, -0.2950, -0.3151],\n",
      "          [-0.3293, -0.3112, -0.2930,  ..., -0.2748, -0.2888, -0.3027],\n",
      "          [-0.3110, -0.2987, -0.2865,  ..., -0.2749, -0.2826, -0.2903],\n",
      "          ...,\n",
      "          [-0.2280, -0.2268, -0.2256,  ..., -0.2680, -0.2969, -0.3259],\n",
      "          [-0.2071, -0.2078, -0.2085,  ..., -0.2731, -0.2994, -0.3257],\n",
      "          [-0.1862, -0.1888, -0.1913,  ..., -0.2782, -0.3018, -0.3255]],\n",
      "\n",
      "         [[-0.0447, -0.0620, -0.0793,  ...,  0.1685,  0.1720,  0.1754],\n",
      "          [ 0.0031, -0.0137, -0.0305,  ...,  0.1706,  0.1685,  0.1664],\n",
      "          [ 0.0509,  0.0346,  0.0183,  ...,  0.1726,  0.1650,  0.1573],\n",
      "          ...,\n",
      "          [ 0.1792,  0.1779,  0.1766,  ...,  0.1615,  0.1516,  0.1417],\n",
      "          [ 0.1471,  0.1532,  0.1592,  ...,  0.1585,  0.1504,  0.1423],\n",
      "          [ 0.1151,  0.1284,  0.1418,  ...,  0.1554,  0.1492,  0.1429]],\n",
      "\n",
      "         [[-0.1824, -0.1801, -0.1778,  ...,  0.1136,  0.0953,  0.0770],\n",
      "          [-0.1671, -0.1623, -0.1574,  ...,  0.0963,  0.0807,  0.0650],\n",
      "          [-0.1519, -0.1444, -0.1370,  ...,  0.0791,  0.0661,  0.0531],\n",
      "          ...,\n",
      "          [-0.0956, -0.0779, -0.0601,  ..., -0.0072,  0.0066,  0.0204],\n",
      "          [-0.1234, -0.0994, -0.0754,  ..., -0.0419, -0.0330, -0.0241],\n",
      "          [-0.1511, -0.1209, -0.0906,  ..., -0.0765, -0.0725, -0.0685]]]],\n",
      "       grad_fn=<UpsampleBilinear2DBackward>))\n"
     ]
    }
   ],
   "source": [
    "# 배치 사이즈 \n",
    "batch_size = 2\n",
    "dummy_img = torch.rand(batch_size, 3, 475, 475)\n",
    "\n",
    "# 계산\n",
    "outputs = net(dummy_img)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61cbe7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 import \n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9789b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import make_datapath_list, DataTransform, VOCDataset\n",
    "\n",
    "# 파일 겨올 리스트 작성\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n",
    "    rootpath=rootpath)\n",
    "\n",
    "# Dataset 작성\n",
    "# (RGB) 색의 평균값과 표준편차\n",
    "color_mean = (0.485, 0.456, 0.406)\n",
    "color_std = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\", transform=DataTransform(\n",
    "    input_size=475, color_mean=color_mean, color_std=color_std))\n",
    "\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(\n",
    "    input_size=475, color_mean=color_mean, color_std=color_std))\n",
    "\n",
    "# DataLoader 작성\n",
    "batch_size = 8\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataloader = data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 사전형 변수로 정의\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dee86f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네트워크 구성 완료: 학습된 가중치를 로드했습니다.\n"
     ]
    }
   ],
   "source": [
    "from utils.pspnet import PSPNet\n",
    "\n",
    "# 파인튜닝으로 PSPNet 작성\n",
    "# ADE20K 데이터셋의 학습된 모델을 사용하며 ADE20K 클래스 수는 150\n",
    "net = PSPNet(n_classes=150)\n",
    "\n",
    "# ADE20K 학습된 파라미터 읽기\n",
    "state_dict = torch.load(\"./weights/pspnet50_ADE20K.pth\")\n",
    "net.load_state_dict(state_dict)\n",
    "\n",
    "# 분류용 합성곱 층을 출력 수 21로 바꾼다.\n",
    "n_classes = 21\n",
    "net.decode_feature.classification = nn.Conv2d(\n",
    "    in_channels=512, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "net.aux.classification = nn.Conv2d(\n",
    "    in_channels=256, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "# 교체한 합성곱 층 초기화. 활성화 함수는 시그모이드 함수이므로 Xavier 사용\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:  # バイアス項がある場合\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "net.decode_feature.classification.apply(weights_init)\n",
    "net.aux.classification.apply(weights_init)\n",
    "\n",
    "\n",
    "print('네트워크 구성 완료: 학습된 가중치를 로드했습니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "921e36ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PSPNet(\n",
       "  (feature_conv): FeatureMap_convolution(\n",
       "    (cbnr_1): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (cbnr_2): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (cbnr_3): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (feature_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (feature_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block5): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block6): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (pyramid_pooling): PyramidPooling(\n",
       "    (avpool_1): AdaptiveAvgPool2d(output_size=6)\n",
       "    (cbr_1): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (avpool_2): AdaptiveAvgPool2d(output_size=3)\n",
       "    (cbr_2): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (avpool_3): AdaptiveAvgPool2d(output_size=2)\n",
       "    (cbr_3): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (avpool_4): AdaptiveAvgPool2d(output_size=1)\n",
       "    (cbr_4): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (decode_feature): DecodePSPFeature(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1)\n",
       "    (classification): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux): AuxiliaryPSPlayers(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1)\n",
       "    (classification): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12a4fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 정의\n",
    "class PSPLoss(nn.Module):\n",
    "    \"\"\"PSPNet손실함수 클래스\"\"\"\n",
    "\n",
    "    def __init__(self, aux_weight=0.4):\n",
    "        super(PSPLoss, self).__init__()\n",
    "        self.aux_weight = aux_weight  # aux_loss의 가중치\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        \"\"\"\n",
    "        손실함수 계산\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        outputs : PSPNet출력(tuple)\n",
    "            (output=torch.Size([num_batch, 21, 475, 475]), output_aux=torch.Size([num_batch, 21, 475, 475]))。\n",
    "\n",
    "        targets : [num_batch, 475, 475]\n",
    "            정답 어노테이션 정보\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : 텐서\n",
    "            손실 값\n",
    "        \"\"\"\n",
    "\n",
    "        loss = F.cross_entropy(outputs[0], targets, reduction='mean')\n",
    "        loss_aux = F.cross_entropy(outputs[1], targets, reduction='mean')\n",
    "\n",
    "        return loss+self.aux_weight*loss_aux\n",
    "\n",
    "\n",
    "criterion = PSPLoss(aux_weight=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4728e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝이므로 학습률은 작게\n",
    "optimizer = optim.SGD([\n",
    "    {'params': net.feature_conv.parameters(), 'lr': 1e-3},\n",
    "    {'params': net.feature_res_1.parameters(), 'lr': 1e-3},\n",
    "    {'params': net.feature_res_2.parameters(), 'lr': 1e-3},\n",
    "    {'params': net.feature_dilated_res_1.parameters(), 'lr': 1e-3},\n",
    "    {'params': net.feature_dilated_res_2.parameters(), 'lr': 1e-3},\n",
    "    {'params': net.pyramid_pooling.parameters(), 'lr': 1e-3},\n",
    "    {'params': net.decode_feature.parameters(), 'lr': 1e-2},\n",
    "    {'params': net.aux.parameters(), 'lr': 1e-2},\n",
    "], momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "# 스케줄러 설정\n",
    "def lambda_epoch(epoch):\n",
    "    max_epoch = 30\n",
    "    return math.pow((1-epoch/max_epoch), 0.9)\n",
    "\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eab47d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 학습시키는 함수 작성\n",
    "def train_model(net, dataloaders_dict, criterion, scheduler, optimizer, num_epochs):\n",
    "\n",
    "    # GPU를 사용할 수 있는지 확인\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "\n",
    "    # 네트워크를 GPU로\n",
    "    net.to(device)\n",
    "\n",
    "    # 네트워크가 어느 정도 고정되면 고속화\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 화상 매수\n",
    "    num_train_imgs = len(dataloaders_dict[\"train\"].dataset)\n",
    "    num_val_imgs = len(dataloaders_dict[\"val\"].dataset)\n",
    "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
    "\n",
    "    # 반복자의 카운터 설정\n",
    "    iteration = 1\n",
    "    logs = []\n",
    "\n",
    "    # multiple minibatch\n",
    "    batch_multiplier = 3\n",
    "\n",
    "    # epoch루프\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # 시작 시간 저장\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "        epoch_train_loss = 0.0  # epoch손실 합\n",
    "        epoch_val_loss = 0.0  # epoch손실 합\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "\n",
    "        # epoch별 훈련 및 검증 루프\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # 모델을 훈련모드로\n",
    "                scheduler.step()  # 최적화 스케줄러 갱신\n",
    "                optimizer.zero_grad()\n",
    "                print('（train）')\n",
    "\n",
    "            else:\n",
    "                if((epoch+1) % 5 == 0):\n",
    "                    net.eval()   # 모델을 검증모드로\n",
    "                    print('-------------')\n",
    "                    print('（val）')\n",
    "                else:\n",
    "                    # 검증은 다섯 번 중 한 번만 수행\n",
    "                    continue\n",
    "\n",
    "            # 데이터 로더에서 미니 배치씩 꺼내 루프\n",
    "            count = 0  # multiple minibatch\n",
    "            for imges, anno_class_imges in dataloaders_dict[phase]:\n",
    "                # 미니 배치 크기가 1이면 배치 정규화에서 오류가 발생하여 피한다..\n",
    "                if imges.size()[0] == 1:\n",
    "                    continue\n",
    "\n",
    "                # GPU를 사용할 수 있으면 GPU에 데이터를 보낸다.\n",
    "                imges = imges.to(device)\n",
    "                anno_class_imges = anno_class_imges.to(device)\n",
    "\n",
    "                \n",
    "                # multiple minibatch로 파라미터 갱신\n",
    "                if (phase == 'train') and (count == 0):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    count = batch_multiplier\n",
    "\n",
    "                # 순전파 계산\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = net(imges)\n",
    "                    loss = criterion(\n",
    "                        outputs, anno_class_imges.long()) / batch_multiplier\n",
    "\n",
    "                    # 훈련 시에는 역전파\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()  # 경사 계산\n",
    "                        count -= 1  # multiple minibatch\n",
    "\n",
    "                        if (iteration % 10 == 0):  # 10iter에 한 번 손실 표시\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print('반복 {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n",
    "                                iteration, loss.item()/batch_size*batch_multiplier, duration))\n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                        epoch_train_loss += loss.item() * batch_multiplier\n",
    "                        iteration += 1\n",
    "\n",
    "                    # 검증 시\n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item() * batch_multiplier\n",
    "\n",
    "        # 에폭의 phase별 손실과 정답률\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n",
    "            epoch+1, epoch_train_loss/num_train_imgs, epoch_val_loss/num_val_imgs))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        # 로그 저장\n",
    "        log_epoch = {'epoch': epoch+1, 'train_loss': epoch_train_loss /\n",
    "                     num_train_imgs, 'val_loss': epoch_val_loss/num_val_imgs}\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        df.to_csv(\"log_output.csv\")\n",
    "\n",
    "    # 마지막 네트워크 저장\n",
    "    torch.save(net.state_dict(), 'weights/pspnet50_' +\n",
    "               str(epoch+1) + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33c509cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 学習・検証を実行する\n",
    "# num_epochs = 30\n",
    "# train_model(net, dataloaders_dict, criterion, scheduler, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bf52f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d3736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import make_datapath_list, DataTransform\n",
    "\n",
    "\n",
    "# ファイルパスリスト作成\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n",
    "    rootpath=rootpath)\n",
    "\n",
    "# 後ほどアノテーション画像のみを使用する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16e5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pspnet import PSPNet\n",
    "\n",
    "net = PSPNet(n_classes=21)\n",
    "\n",
    "# 学習済みパラメータをロード\n",
    "state_dict = torch.load(\"./weights/pspnet50_30.pth\",\n",
    "                        map_location={'cuda:0': 'cpu'})\n",
    "net.load_state_dict(state_dict)\n",
    "\n",
    "print('ネットワーク設定完了：学習済みの重みをロードしました')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec8e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
