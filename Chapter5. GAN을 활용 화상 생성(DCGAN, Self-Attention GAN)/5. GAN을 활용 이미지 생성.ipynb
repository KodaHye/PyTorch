{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50185714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tarfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4283069",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e55b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09c78a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c744a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, data_home=\"./data/\", as_frame=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bb0fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.data\n",
    "y = mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1fc5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[0].reshape(28, 28), cmap='gray')\n",
    "print(\"この画像データのラベルは{}です\".format(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edc34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = \"./data/img_78/\"\n",
    "if not os.path.exists(data_dir_path):\n",
    "    os.mkdir(data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e9be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count7=0\n",
    "count8=0\n",
    "max_num=200\n",
    "\n",
    "for i in range(len(X)):\n",
    "    \n",
    "    if (y[i] is \"7\") and (count7<max_num):\n",
    "        file_path=\"./data/img_78/img_7_\"+str(count7)+\".jpg\"\n",
    "        im_f=(X[i].reshape(28, 28))\n",
    "        pil_img_f = Image.fromarray(im_f.astype(np.uint8)) \n",
    "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC) \n",
    "        pil_img_f.save(file_path)\n",
    "        count7+=1 \n",
    "    \n",
    "    if (y[i] is \"8\") and (count8<max_num):\n",
    "        file_path=\"./data/img_78/img_8_\"+str(count8)+\".jpg\"\n",
    "        im_f=(X[i].reshape(28, 28))\n",
    "        pil_img_f = Image.fromarray(im_f.astype(np.uint8)) \n",
    "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC) \n",
    "        pil_img_f.save(file_path) \n",
    "        count8+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02711c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 import\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c899dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3112a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = torch.tensor([[[[1., 1.], [2., 2.]]]])\n",
    "# print(\"入力データ\")\n",
    "# print(input)\n",
    "# print(\"-----\")\n",
    "\n",
    "# print(\"通常の畳み込み\")\n",
    "# m = nn.Conv2d(1, 1, 2, stride=1, bias=False)\n",
    "# m.weight.data[0, 0, 0, 0] = 1\n",
    "# m.weight.data[0, 0, 0, 1] = 2\n",
    "# m.weight.data[0, 0, 1, 0] = 3\n",
    "# m.weight.data[0, 0, 1, 1] = 4\n",
    "# print(\"カーネル\")\n",
    "# print(m.weight)\n",
    "# print(\"出力\")\n",
    "# print(m(input))\n",
    "\n",
    "# print(\"-----\")\n",
    "# print(\"転置畳み込み\")\n",
    "# m = nn.ConvTranspose2d(1, 1, 2, stride=1, bias=False)\n",
    "# m.weight.data[0, 0, 0, 0] = 1\n",
    "# m.weight.data[0, 0, 0, 1] = 2\n",
    "# m.weight.data[0, 0, 1, 0] = 3\n",
    "# m.weight.data[0, 0, 1, 1] = 4\n",
    "# print(\"カーネル\")\n",
    "# print(m.weight)\n",
    "# print(\"出力\")\n",
    "# print(m(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim=20, image_size=64):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, image_size * 8,\n",
    "                               kernel_size=4, stride=1),\n",
    "            nn.BatchNorm2d(image_size * 8),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size * 8, image_size * 4,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size * 4),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size * 4, image_size * 2,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size * 2),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size * 2, image_size,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.last = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size, 1, kernel_size=4,\n",
    "                               stride=2, padding=1),\n",
    "            nn.Tanh())\n",
    "        # 주의: 흑백 이미지이므로 출력 채널은 하나 뿐\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.layer1(z)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.last(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d53eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동작확인\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "G = Generator(z_dim=20, image_size=64)\n",
    "\n",
    "# 난수 입력\n",
    "input_z = torch.randn(1, 20)\n",
    "\n",
    "# 텐서 크기 (1, 20, 1, 1)으로 변경\n",
    "input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "\n",
    "# 가짜 이미지 출력\n",
    "fake_images = G(input_z)\n",
    "\n",
    "img_transformed = fake_images[0][0].detach().numpy()\n",
    "plt.imshow(img_transformed, 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f61461",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim=20, image_size=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, image_size, kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "        # 주의: 흑백 이미지이므로 입력 채널은 하나뿐\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(image_size, image_size*2, kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(image_size*2, image_size*4, kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(image_size*4, image_size*8, kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.last = nn.Conv2d(image_size*8, 1, kernel_size=4, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.last(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694e6d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동작확인\n",
    "D = Discriminator(z_dim=20, image_size=64)\n",
    "\n",
    "# 가짜 이미지 생성\n",
    "input_z = torch.randn(1, 20)\n",
    "input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "fake_images = G(input_z)\n",
    "\n",
    "# 가짜 이미지를 D에 입력\n",
    "d_out = D(fake_images)\n",
    "\n",
    "# 출력 d_out에 시그모이드를 곱하여 0에서 1로 변환\n",
    "print(nn.Sigmoid()(d_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef14f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D 오차 함수의 이미지 구현\n",
    "# maximize log(D(x)) + log(1 - D(G(z)))\n",
    "\n",
    "\n",
    "# ※ x가 정의되지 않아 오류 발생\n",
    "#---------------\n",
    "\n",
    "\n",
    "# 정답 라벨 작성\n",
    "mini_batch_size = 2\n",
    "label_real = torch.full((mini_batch_size,), 1)\n",
    "\n",
    "# 가짜 라벨 작성\n",
    "label_fake = torch.full((mini_batch_size,), 0)\n",
    "\n",
    "# 오차 함수 정의\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "# 진짜 이미지 판정\n",
    "d_out_real = D(x)\n",
    "\n",
    "# 가짜 이미지를 생성하여 판정\n",
    "input_z = torch.randn(mini_batch_size, 20)\n",
    "input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "fake_images = G(input_z)\n",
    "d_out_fake = D(fake_images)\n",
    "\n",
    "# 오차 계산\n",
    "d_loss_real = criterion(d_out_real.view(-1), label_real)\n",
    "d_loss_fake = criterion(d_out_fake.view(-1), label_fake)\n",
    "d_loss = d_loss_real + d_loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fafcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G의 오차 함수 이미지 구현\n",
    "# maximize log(D(G(z)))\n",
    "\n",
    "\n",
    "# ※ x가 정의되지 않아 오류 발생\n",
    "#---------------\n",
    "\n",
    "\n",
    "# 가짜 이미지를 생성하여 판정\n",
    "input_z = torch.randn(mini_batch_size, 20)\n",
    "input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "fake_images = G(input_z)\n",
    "d_out_fake = D(fake_images)\n",
    "\n",
    "# 오차 계산\n",
    "g_loss = criterion(d_out_fake.view(-1), label_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dec4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datapath_list():\n",
    "    \"\"\"학습 및 검증 이미지 데이터와 어노테이션 데이터의 파일 경로 리스트 작성 \"\"\"\n",
    "\n",
    "    train_img_list = list()  # 이미지 파일 경로 저장\n",
    "\n",
    "    for img_idx in range(200):\n",
    "        img_path = \"./data/img_78/img_7_\" + str(img_idx)+'.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "\n",
    "        img_path = \"./data/img_78/img_8_\" + str(img_idx)+'.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "\n",
    "    return train_img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9447e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "    \"\"\"이미지의 전처리 클래스\"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.data_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.data_transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aced39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_Img_Dataset(data.Dataset):\n",
    "    \"\"\"이미지의 데이터셋 클래스. 파이토치의 데이터셋 클래스를 상속\"\"\"\n",
    "\n",
    "    def __init__(self, file_list, transform):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        '''이미지 매수 반환'''\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''전처리한 이미지의 텐서 형식 데이터 취득'''\n",
    "\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)  # [높이][폭]흑백\n",
    "\n",
    "        # 이미지 전처리\n",
    "        img_transformed = self.transform(img)\n",
    "\n",
    "        return img_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0161cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 작성과 동작 확인\n",
    "\n",
    "# 파일 리스트 작성\n",
    "train_img_list=make_datapath_list()\n",
    "\n",
    "# Dataset 작성\n",
    "mean = (0.5,)\n",
    "std = (0.5,)\n",
    "train_dataset = GAN_Img_Dataset(\n",
    "    file_list=train_img_list, transform=ImageTransform(mean, std))\n",
    "\n",
    "# DataLoader 작성\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 동작 확인\n",
    "batch_iterator = iter(train_dataloader)  # 반복자로 변환\n",
    "imges = next(batch_iterator)  # 첫 번째 요소를 꺼낸다.\n",
    "print(imges.size())  # torch.Size([64, 1, 64, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c9ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네트워크 초기화\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        # Conv2dとConvTranspose2d 초기화\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        # BatchNorm2d 초기화\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "# 초기화 실시\n",
    "G.apply(weights_init)\n",
    "D.apply(weights_init)\n",
    "\n",
    "print(\"네트워크 초기화 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bf40c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 학습시키는 함수 작성\n",
    "\n",
    "def train_model(G, D, dataloader, num_epochs):\n",
    "\n",
    "    # GPU를 사용할 수 있는지 확인\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"사용 장치：\", device)\n",
    "\n",
    "    # 최적화 기법 설정\n",
    "    g_lr, d_lr = 0.0001, 0.0004\n",
    "    beta1, beta2 = 0.0, 0.9\n",
    "    g_optimizer = torch.optim.Adam(G.parameters(), g_lr, [beta1, beta2])\n",
    "    d_optimizer = torch.optim.Adam(D.parameters(), d_lr, [beta1, beta2])\n",
    "\n",
    "    # 오차함수 정의\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "    # 파라미터를 하드코딩\n",
    "    z_dim = 20\n",
    "    mini_batch_size = 64\n",
    "\n",
    "    # 네트워크를 GPU로\n",
    "    G.to(device)\n",
    "    D.to(device)\n",
    "\n",
    "    G.train()  # 모델을 훈련모드로\n",
    "    D.train()  # 모델을 훈련모드로\n",
    "\n",
    "    # 네트워크가 어느 정도 고정되면 고속화시킨다.\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 이미지 매수\n",
    "    num_train_imgs = len(dataloader.dataset)\n",
    "    batch_size = dataloader.batch_size\n",
    "\n",
    "    # 반복 카운터 설정\n",
    "    iteration = 1\n",
    "    logs = []\n",
    "\n",
    "    # 에폭 루프\n",
    "    for epoch in range(num_epochs):\n",
    "        # 개시 시간 저장\n",
    "        t_epoch_start = time.time()\n",
    "        epoch_g_loss = 0.0  # 에폭의 손실 합\n",
    "        epoch_d_loss = 0.0  # 에폭의 손실 합\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-------------')\n",
    "        print('（train）')\n",
    "\n",
    "        # 데이터 로더에서 미니 배치씩 꺼내는 루프\n",
    "        for imges in dataloader:\n",
    "\n",
    "            # --------------------\n",
    "            # 1. Discriminator 학습\n",
    "            # --------------------\n",
    "            # 미니 배치 크기가 1이면 배치 정규화에서 오류가 발생하므로 피한다.\n",
    "            if imges.size()[0] == 1:\n",
    "                continue\n",
    "\n",
    "            # GPU를 사용할 수 있다면 GPU로 데이터를 보낸다.\n",
    "            imges = imges.to(device)\n",
    "\n",
    "            # 정답 라벨과 가짜 라벨 작성\n",
    "            # 에폭의 마지막 반복은 미니 배치 수가 줄어든다.\n",
    "            mini_batch_size = imges.size()[0]\n",
    "            label_real = torch.full((mini_batch_size,), 1).to(device)\n",
    "            label_fake = torch.full((mini_batch_size,), 0).to(device)\n",
    "\n",
    "            # 진짜 이미지 판정\n",
    "            d_out_real = D(imges)\n",
    "\n",
    "            # 가짜 이미지를 생성하여 판정\n",
    "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
    "            input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "            fake_images = G(input_z)\n",
    "            d_out_fake = D(fake_images)\n",
    "\n",
    "            # 오차 계산\n",
    "            d_loss_real = criterion(d_out_real.view(-1), label_real)\n",
    "            d_loss_fake = criterion(d_out_fake.view(-1), label_fake)\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "            # 역전파\n",
    "            g_optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # --------------------\n",
    "            # 2. Generator 학습\n",
    "            # --------------------\n",
    "            # 가짜 이미지를 생성하여 판정\n",
    "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
    "            input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "            fake_images = G(input_z)\n",
    "            d_out_fake = D(fake_images)\n",
    "\n",
    "            # 오차 계산\n",
    "            g_loss = criterion(d_out_fake.view(-1), label_real)\n",
    "\n",
    "            # 역전파\n",
    "            g_optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            # --------------------\n",
    "            # 3. 기록\n",
    "            # --------------------\n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            iteration += 1\n",
    "\n",
    "        # 에폭의 phase별 손실과 정답률\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('epoch {} || Epoch_D_Loss:{:.4f} ||Epoch_G_Loss:{:.4f}'.format(\n",
    "            epoch, epoch_d_loss/batch_size, epoch_g_loss/batch_size))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "    return G, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 검증 실행\n",
    "# 6분 정도 걸림\n",
    "num_epochs = 200\n",
    "G_update, D_update = train_model(\n",
    "    G, D, dataloader=train_dataloader, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f78d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성 이미지와 훈련 데이터 시각화\n",
    "# 이 셀은 괜찮은 느낌의 이미지가 생성될 떄까지 재실행한다.\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 입력 난수 생성\n",
    "batch_size = 8\n",
    "z_dim = 20\n",
    "fixed_z = torch.randn(batch_size, z_dim)\n",
    "fixed_z = fixed_z.view(fixed_z.size(0), fixed_z.size(1), 1, 1)\n",
    "\n",
    "# 이미지 생성\n",
    "G_update.eval()\n",
    "fake_images = G_update(fixed_z.to(device))\n",
    "\n",
    "# 훈련 데이턴\n",
    "batch_iterator = iter(train_dataloader)  # 반복자로 변환\n",
    "imges = next(batch_iterator)  # 첫 번째 요소를 꺼낸다.\n",
    "\n",
    "\n",
    "# 출력\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i in range(0, 5):\n",
    "    # 상단에 훈련 데이터 표시\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n",
    "\n",
    "    # 하단에 생성 데이터를 표시\n",
    "    plt.subplot(2, 5, 5+i+1)\n",
    "    plt.imshow(fake_images[i][0].cpu().detach().numpy(), 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552752aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attentiom Map을 출력\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i in range(0, 5):\n",
    "\n",
    "    # 상단에 생성한 이미지 데이터 표시\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(fake_images[i][0].cpu().detach().numpy(), 'gray')\n",
    "\n",
    "    # 하단에 Attention Map 1 이미지\n",
    "    plt.subplot(2, 5, 5+i+1)\n",
    "    am = am1[i].view(16, 16, 16, 16)\n",
    "    am = am[7][7]  # 중앙에 주목\n",
    "    plt.imshow(am.cpu().detach().numpy(), 'Reds')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_pytorch",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
