{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02dafc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tarfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f030385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data 폴더가 없으면 작성한다\n",
    "data_dir = \"./data/\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "894158b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "\n",
    "# AWS의 AMI에서 sklern의 version이 0.20보다 낮은 경우에는 버전을 업데이트합니다\n",
    "# pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68c194d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST의 필기체 숫자 화상을 다운로드하여 읽습니다\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, data_home=\"./data/\")  # data_home으로 저장 위치를 지정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfae524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 꺼내기\n",
    "X = mnist.data\n",
    "y = mnist.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "271e3577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 화상 데이터의 라벨은 5입니다\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MNIST의 데이터 첫 번째를 시각화\n",
    "plt.imshow(X[0].reshape(28, 28), cmap='gray')\n",
    "print(\"이 화상 데이터의 라벨은 {}입니다\".format(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44d786d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"data\" 폴더의 아래에 \"img_78\" 폴더를 작성한다\n",
    "data_dir_path = \"./data/img_78/\"\n",
    "if not os.path.exists(data_dir_path):\n",
    "    os.mkdir(data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19117ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST에서 숫자7, 8의 화상만 \"img_78\" 폴더에 화상으로 저장해 나간다\n",
    "count7=0\n",
    "count8=0\n",
    "max_num=200  # 화상은 200장씩 작성한다\n",
    "\n",
    "for i in range(len(X)):\n",
    "    \n",
    "    # 화상7 작성\n",
    "    if (y[i] is \"7\") and (count7<max_num):\n",
    "        file_path=\"./data/img_78/img_7_\"+str(count7)+\".jpg\"\n",
    "        im_f=(X[i].reshape(28, 28))  # 화상을 28×28의 형태로 변경\n",
    "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 화상을 PIL으로\n",
    "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC)  # 64×64로 확대\n",
    "        pil_img_f.save(file_path)  # 저장\n",
    "        count7+=1 \n",
    "    \n",
    "    # 화상8 작성\n",
    "    if (y[i] is \"8\") and (count8<max_num):\n",
    "        file_path=\"./data/img_78/img_8_\"+str(count8)+\".jpg\"\n",
    "        im_f=(X[i].reshape(28, 28))  # 화상을 28×28의 형태로 변경\n",
    "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 화상을 PIL으로\n",
    "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC)  # 64×64로 확대\n",
    "        pil_img_f.save(file_path)  # 저장\n",
    "        count8+=1\n",
    "        \n",
    "    # 7과 8을 200장씩 작성했다면 break\n",
    "    if (count7>=max_num) and (count8>=max_num):\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33b44444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"data\" 폴더의 아래에 \"test\" 폴더를 작성한다\n",
    "data_dir_path = \"./data/test/\"\n",
    "if not os.path.exists(data_dir_path):\n",
    "    os.mkdir(data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "379ca8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2244\n"
     ]
    }
   ],
   "source": [
    "# 위에서 7,8의 화상 작성에 사용한 index의 최종값\n",
    "i_start = i+1\n",
    "print(i_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f97112f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST에서 숫자2, 7, 8의 화상만 \"test\" 폴더에 화상으로 저장해 나간다\n",
    "count2=0\n",
    "count7=0\n",
    "count8=0\n",
    "max_num=5  # 화상은 5장씩 작성한다\n",
    "\n",
    "for i in range(i_start,len(X)):  # i_start에서 시작\n",
    "    \n",
    "    # 화상2 작성\n",
    "    if (y[i] is \"2\") and (count2<max_num):\n",
    "        file_path=\"./data/test/img_2_\"+str(count2)+\".jpg\"\n",
    "        im_f=(X[i].reshape(28, 28))  # 화상을 28×28의 형태로 변경\n",
    "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 화상을 PIL으로\n",
    "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC)  # 64×64로 확대\n",
    "        pil_img_f.save(file_path)  # 저장\n",
    "        count2+=1\n",
    "    \n",
    "    # 화상7 작성\n",
    "    if (y[i] is \"7\") and (count7<max_num):\n",
    "        file_path=\"./data/test/img_7_\"+str(count7)+\".jpg\"\n",
    "        im_f=(X[i].reshape(28, 28))  # 화상을 28×28의 형태로 변경\n",
    "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 화상을 PIL으로\n",
    "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC)  # 64×64로 확대\n",
    "        pil_img_f.save(file_path)  # 저장\n",
    "        count7+=1 \n",
    "    \n",
    "    # 화상8 작성\n",
    "    if (y[i] is \"8\") and (count8<max_num):\n",
    "        file_path=\"./data/test/img_8_\"+str(count8)+\".jpg\"\n",
    "        im_f=(X[i].reshape(28, 28))  # 화상을 28×28의 형태로 변경\n",
    "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 화상을 PIL으로\n",
    "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC)  # 64×64로 확대\n",
    "        pil_img_f.save(file_path)  # 저장\n",
    "        count8+=1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d0bf2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"data\" 폴더의 아래에 \"img_78_28size\" 폴더를 작성한다\n",
    "data_dir_path = \"./data/img_78_28size/\"\n",
    "if not os.path.exists(data_dir_path):\n",
    "    os.mkdir(data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13734146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST에서 숫자7, 8의 화상만 \"img_78_28size\" 폴더에 화상으로 저장해 나간다\n",
    "count7=0\n",
    "count8=0\n",
    "max_num=200  # 화상은 200장씩 작성한다\n",
    "\n",
    "for i in range(len(X)):\n",
    "    \n",
    "    # 화상7 작성\n",
    "    if (y[i] is \"7\") and (count7<max_num):\n",
    "        file_path=\"./data/img_78_28size/img_7_\"+str(count7)+\".jpg\"\n",
    "        im_f=(X[i].reshape(28, 28))  # 화상을 28×28의 형태로 변경\n",
    "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 화상을 PIL으로\n",
    "        pil_img_f.save(file_path)  # 저장\n",
    "        count7+=1 \n",
    "    \n",
    "    # 화상8 작성\n",
    "    if (y[i] is \"8\") and (count8<max_num):\n",
    "        file_path=\"./data/img_78_28size/img_8_\"+str(count8)+\".jpg\"\n",
    "        im_f=(X[i].reshape(28, 28))  # 화상을 28×28의 형태로 변경\n",
    "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 화상을 PIL으로\n",
    "        pil_img_f.save(file_path)  # 저장\n",
    "        count8+=1\n",
    "    \n",
    "    if (count7>=max_num) and (count8>=max_num):\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b32503a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2244\n"
     ]
    }
   ],
   "source": [
    "# \"data\" 폴더의 아래에 \"test_28size\" 폴더를 작성한다\n",
    "data_dir_path = \"./data/test_28size/\"\n",
    "if not os.path.exists(data_dir_path):\n",
    "    os.mkdir(data_dir_path)\n",
    "\n",
    "# 위에서 7,8의 화상 작성에 사용한 index의 최종값\n",
    "i_start = i+1\n",
    "print(i_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46e57bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST에서 숫자2, 7, 8의 화상만 \"test_28size\" 폴더에 화상으로 저장해 나간다\n",
    "count2=0\n",
    "count7=0\n",
    "count8=0\n",
    "max_num=5  # 화상은 5장씩 작성한다\n",
    "\n",
    "for i in range(i_start,len(X)):  # i_start에서 시작\n",
    "    \n",
    "    # 화상2 작성\n",
    "    if (y[i] is \"2\") and (count2<max_num):\n",
    "        file_path=\"./data/test_28size/img_2_\"+str(count2)+\".jpg\"\n",
    "        im_f=(X[i].reshape(28, 28))  # 화상을 28×28의 형태로 변경\n",
    "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 화상을 PIL으로\n",
    "        pil_img_f.save(file_path)  # 저장\n",
    "        count2+=1 \n",
    "    \n",
    "    # 화상7 작성\n",
    "    if (y[i] is \"7\") and (count7<max_num):\n",
    "        file_path=\"./data/test_28size/img_7_\"+str(count7)+\".jpg\"\n",
    "        im_f=(X[i].reshape(28, 28))  # 화상을 28×28의 형태로 변경\n",
    "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 화상을 PIL으로\n",
    "        pil_img_f.save(file_path)  # 저장\n",
    "        count7+=1 \n",
    "    \n",
    "    # 화상8 작성\n",
    "    if (y[i] is \"8\") and (count8<max_num):\n",
    "        file_path=\"./data/test_28size/img_8_\"+str(count8)+\".jpg\"\n",
    "        im_f=(X[i].reshape(28, 28))  # 화상을 28×28의 형태로 변경\n",
    "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 화상을 PIL으로\n",
    "        pil_img_f.save(file_path)  # 저장\n",
    "        count8+=1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0029d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 import\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40a69289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b78afdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim=20, image_size=64):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, image_size * 8,\n",
    "                               kernel_size=4, stride=1),\n",
    "            nn.BatchNorm2d(image_size * 8),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size * 8, image_size * 4,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size * 4),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size * 4, image_size * 2,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size * 2),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size * 2, image_size,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(image_size),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.last = nn.Sequential(\n",
    "            nn.ConvTranspose2d(image_size, 1, kernel_size=4,\n",
    "                               stride=2, padding=1),\n",
    "            nn.Tanh())\n",
    "        # 주의: 흑백 화상이므로, 출력 채널은 하나 뿐임\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.layer1(z)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.last(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3af2ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 동작 확인\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "G = Generator(z_dim=20, image_size=64)\n",
    "\n",
    "# 압력 난수\n",
    "input_z = torch.randn(1, 20)\n",
    "\n",
    "# 텐서 사이즈를 (1, 20, 1, 1)로 변형\n",
    "input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "\n",
    "# 가짜 화상을 출력\n",
    "fake_images = G(input_z)\n",
    "\n",
    "img_transformed = fake_images[0][0].detach().numpy()\n",
    "plt.imshow(img_transformed, 'gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fa53c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim=20, image_size=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, image_size, kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "        # 주의: 흑백 화상이므로 입력 채널은 하나 뿐임\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(image_size, image_size*2, kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(image_size*2, image_size*4, kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(image_size*4, image_size*8, kernel_size=4,\n",
    "                      stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.last = nn.Conv2d(image_size*8, 1, kernel_size=4, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        feature = out  # 최후에 채널을 하나로 집약\n",
    "        feature = feature.view(feature.size()[0], -1)  # 2차원으로 변환\n",
    "\n",
    "        out = self.last(out)\n",
    "\n",
    "        return out, feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be3c53f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.4973]]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([1, 8192])\n"
     ]
    }
   ],
   "source": [
    "# 동작 확인\n",
    "D = Discriminator(z_dim=20, image_size=64)\n",
    "\n",
    "# 가짜 화상 생성\n",
    "input_z = torch.randn(1, 20)\n",
    "input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "fake_images = G(input_z)\n",
    "\n",
    "# 가짜 화상을 D에 입력\n",
    "d_out = D(fake_images)\n",
    "\n",
    "# 출력 d_out에 Sigmoid를 곱해 0에서 1로 변환\n",
    "print(nn.Sigmoid()(d_out[0]))\n",
    "\n",
    "# feature\n",
    "print(d_out[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "064a0671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datapath_list():\n",
    "    \"\"\"학습 및 검증 화상 데이터와 어노테이션 데이터의 파일 경로 리스트를 작성한다. \"\"\"\n",
    "\n",
    "    train_img_list = list()  # 화상 파일 경로를 저장\n",
    "\n",
    "    for img_idx in range(200):\n",
    "        img_path = \"./data/img_78/img_7_\" + str(img_idx)+'.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "\n",
    "        img_path = \"./data/img_78/img_8_\" + str(img_idx)+'.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "\n",
    "    return train_img_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c208727",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "    \"\"\"화상의 전처리 클래스\"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.data_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.data_transform(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78701e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_Img_Dataset(data.Dataset):\n",
    "    \"\"\"화상의 Dataset 클래스. PyTorch의 Dataset 클래스를 상속\"\"\"\n",
    "\n",
    "    def __init__(self, file_list, transform):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        '''화상 매수를 반환한다'''\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''전처리한 화상의 Tensor 형식 데이터 취득'''\n",
    "\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)  # [높이][폭]흑백\n",
    "\n",
    "        # 화상 전처리\n",
    "        img_transformed = self.transform(img)\n",
    "\n",
    "        return img_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6d91502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# DataLoader 작성과 동작 확인\n",
    "\n",
    "# 파일 리스트를 작성\n",
    "train_img_list=make_datapath_list()\n",
    "\n",
    "# Dataset 작성\n",
    "mean = (0.5,)\n",
    "std = (0.5,)\n",
    "train_dataset = GAN_Img_Dataset(\n",
    "    file_list=train_img_list, transform=ImageTransform(mean, std))\n",
    "\n",
    "# DataLoader 작성\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 동작 확인\n",
    "batch_iterator = iter(train_dataloader)  # 반복자로 변환\n",
    "imges = next(batch_iterator)  # 1번째 요소를 꺼낸다\n",
    "print(imges.size())  # torch.Size([64, 1, 64, 64])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9899929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네트워크 초기화 완료\n"
     ]
    }
   ],
   "source": [
    "# 네트워크 초기화\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        # Conv2dとConvTranspose2d 초기화\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        # BatchNorm2d 초기화\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "# 초기화 실시\n",
    "G.apply(weights_init)\n",
    "D.apply(weights_init)\n",
    "\n",
    "print(\"네트워크 초기화 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6096783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 학습시키는 함수를 작성\n",
    "def train_model(G, D, dataloader, num_epochs):\n",
    "\n",
    "    # GPU가 사용 가능한지 확인\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"사용 장치: \", device)\n",
    "\n",
    "    # 최적화 기법 설정\n",
    "    g_lr, d_lr = 0.0001, 0.0004\n",
    "    beta1, beta2 = 0.0, 0.9\n",
    "    g_optimizer = torch.optim.Adam(G.parameters(), g_lr, [beta1, beta2])\n",
    "    d_optimizer = torch.optim.Adam(D.parameters(), d_lr, [beta1, beta2])\n",
    "\n",
    "    # 오차함수 정의\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "    # 파라미터를 하드코딩\n",
    "    z_dim = 20\n",
    "    mini_batch_size = 64\n",
    "\n",
    "    # 네트워크를 GPU로\n",
    "    G.to(device)\n",
    "    D.to(device)\n",
    "\n",
    "    G.train()  # 모델을 훈련 모드로\n",
    "    D.train()  # 모델을 훈련 모드로\n",
    "\n",
    "    # 네트워크가 어느 정도 고정되면, 고속화시킨다\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 화상의 매수\n",
    "    num_train_imgs = len(dataloader.dataset)\n",
    "    batch_size = dataloader.batch_size\n",
    "\n",
    "    # 반복 카운터 설정\n",
    "    iteration = 1\n",
    "    logs = []\n",
    "\n",
    "    # epoch 루프\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # 개시 시간을 저장\n",
    "        t_epoch_start = time.time()\n",
    "        epoch_g_loss = 0.0  # epoch의 손실합\n",
    "        epoch_d_loss = 0.0  # epoch의 손실합\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-------------')\n",
    "        print('(train)')\n",
    "\n",
    "        # 데이터 로더에서 minibatch씩 꺼내는 루프\n",
    "        for imges in dataloader:\n",
    "\n",
    "            # --------------------\n",
    "            # 1. Discriminator 학습\n",
    "            # --------------------\n",
    "            # 미니 배치 크기가 1이면, 배치 노멀라이제이션에서 에러가 발생하므로 피한다\n",
    "            if imges.size()[0] == 1:\n",
    "                continue\n",
    "\n",
    "            # GPU가 사용 가능하면 GPU로 데이터를 보낸다\n",
    "            imges = imges.to(device)\n",
    "\n",
    "            # 정답 라벨과 가짜 라벨 작성\n",
    "            # epoch의 마지막 반복은 미니 배치 수가 줄어든다\n",
    "            mini_batch_size = imges.size()[0]\n",
    "            label_real = torch.full((mini_batch_size,), 1).to(device)\n",
    "            label_fake = torch.full((mini_batch_size,), 0).to(device)\n",
    "\n",
    "            # 진짜 화상을 판정\n",
    "            d_out_real, _ = D(imges)\n",
    "\n",
    "            # 가짜 화상을 생성해 판정\n",
    "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
    "            input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "            fake_images = G(input_z)\n",
    "            d_out_fake, _ = D(fake_images)\n",
    "\n",
    "            # 오차를 계산\n",
    "            d_loss_real = criterion(d_out_real.view(-1), label_real)\n",
    "            d_loss_fake = criterion(d_out_fake.view(-1), label_fake)\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "            # 역전파\n",
    "            g_optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # --------------------\n",
    "            # 2. Generator 학습\n",
    "            # --------------------\n",
    "            # 가짜 화상을 생성해 판정\n",
    "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
    "            input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "            fake_images = G(input_z)\n",
    "            d_out_fake, _ = D(fake_images)\n",
    "\n",
    "            # 오차를 계산\n",
    "            g_loss = criterion(d_out_fake.view(-1), label_real)\n",
    "\n",
    "            # 역전파\n",
    "            g_optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            # --------------------\n",
    "            # 3. 기록\n",
    "            # --------------------\n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            iteration += 1\n",
    "\n",
    "        # epoch의 phase별 loss와 정답률\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('epoch {} || Epoch_D_Loss:{:.4f} ||Epoch_G_Loss:{:.4f}'.format(\n",
    "            epoch, epoch_d_loss/batch_size, epoch_g_loss/batch_size))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "    \n",
    "    print(\"총 반복 횟수: \", iteration)\n",
    "\n",
    "    return G, D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce35079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 장치:  cpu\n",
      "-------------\n",
      "Epoch 0/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 0 || Epoch_D_Loss:0.0546 ||Epoch_G_Loss:0.4326\n",
      "timer:  13.8331 sec.\n",
      "-------------\n",
      "Epoch 1/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 1 || Epoch_D_Loss:0.0008 ||Epoch_G_Loss:0.5700\n",
      "timer:  14.3533 sec.\n",
      "-------------\n",
      "Epoch 2/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 2 || Epoch_D_Loss:0.0004 ||Epoch_G_Loss:0.6503\n",
      "timer:  14.4881 sec.\n",
      "-------------\n",
      "Epoch 3/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 3 || Epoch_D_Loss:0.0003 ||Epoch_G_Loss:0.7115\n",
      "timer:  14.5017 sec.\n",
      "-------------\n",
      "Epoch 4/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 4 || Epoch_D_Loss:0.2609 ||Epoch_G_Loss:0.4875\n",
      "timer:  14.3865 sec.\n",
      "-------------\n",
      "Epoch 5/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 5 || Epoch_D_Loss:0.0389 ||Epoch_G_Loss:0.1745\n",
      "timer:  14.5674 sec.\n",
      "-------------\n",
      "Epoch 6/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 6 || Epoch_D_Loss:0.0088 ||Epoch_G_Loss:0.3403\n",
      "timer:  14.6283 sec.\n",
      "-------------\n",
      "Epoch 7/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 7 || Epoch_D_Loss:0.0036 ||Epoch_G_Loss:0.4685\n",
      "timer:  14.6785 sec.\n",
      "-------------\n",
      "Epoch 8/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 8 || Epoch_D_Loss:0.1625 ||Epoch_G_Loss:0.2514\n",
      "timer:  14.5961 sec.\n",
      "-------------\n",
      "Epoch 9/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 9 || Epoch_D_Loss:0.0055 ||Epoch_G_Loss:0.4519\n",
      "timer:  14.8409 sec.\n",
      "-------------\n",
      "Epoch 10/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 10 || Epoch_D_Loss:0.0019 ||Epoch_G_Loss:0.5712\n",
      "timer:  15.0111 sec.\n",
      "-------------\n",
      "Epoch 11/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 11 || Epoch_D_Loss:0.1062 ||Epoch_G_Loss:0.4748\n",
      "timer:  14.8119 sec.\n",
      "-------------\n",
      "Epoch 12/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 12 || Epoch_D_Loss:0.0050 ||Epoch_G_Loss:0.4140\n",
      "timer:  14.9358 sec.\n",
      "-------------\n",
      "Epoch 13/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 13 || Epoch_D_Loss:0.0101 ||Epoch_G_Loss:0.6595\n",
      "timer:  14.9664 sec.\n",
      "-------------\n",
      "Epoch 14/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 14 || Epoch_D_Loss:0.1858 ||Epoch_G_Loss:0.5981\n",
      "timer:  15.6545 sec.\n",
      "-------------\n",
      "Epoch 15/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 15 || Epoch_D_Loss:0.0104 ||Epoch_G_Loss:0.3844\n",
      "timer:  16.7153 sec.\n",
      "-------------\n",
      "Epoch 16/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 16 || Epoch_D_Loss:0.0045 ||Epoch_G_Loss:0.4854\n",
      "timer:  15.7251 sec.\n",
      "-------------\n",
      "Epoch 17/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 17 || Epoch_D_Loss:0.0034 ||Epoch_G_Loss:0.5603\n",
      "timer:  15.6188 sec.\n",
      "-------------\n",
      "Epoch 18/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 18 || Epoch_D_Loss:0.1971 ||Epoch_G_Loss:0.4546\n",
      "timer:  15.3215 sec.\n",
      "-------------\n",
      "Epoch 19/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 19 || Epoch_D_Loss:0.0164 ||Epoch_G_Loss:0.3891\n",
      "timer:  15.6456 sec.\n",
      "-------------\n",
      "Epoch 20/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 20 || Epoch_D_Loss:0.0805 ||Epoch_G_Loss:0.3873\n",
      "timer:  15.4948 sec.\n",
      "-------------\n",
      "Epoch 21/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 21 || Epoch_D_Loss:0.0069 ||Epoch_G_Loss:0.3998\n",
      "timer:  15.5343 sec.\n",
      "-------------\n",
      "Epoch 22/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 22 || Epoch_D_Loss:0.2004 ||Epoch_G_Loss:0.5167\n",
      "timer:  15.7529 sec.\n",
      "-------------\n",
      "Epoch 23/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 23 || Epoch_D_Loss:0.0191 ||Epoch_G_Loss:0.2737\n",
      "timer:  16.2642 sec.\n",
      "-------------\n",
      "Epoch 24/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 24 || Epoch_D_Loss:0.0681 ||Epoch_G_Loss:0.3726\n",
      "timer:  16.5354 sec.\n",
      "-------------\n",
      "Epoch 25/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 25 || Epoch_D_Loss:0.0411 ||Epoch_G_Loss:0.2935\n",
      "timer:  15.9879 sec.\n",
      "-------------\n",
      "Epoch 26/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 26 || Epoch_D_Loss:0.1380 ||Epoch_G_Loss:0.3457\n",
      "timer:  15.6533 sec.\n",
      "-------------\n",
      "Epoch 27/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 27 || Epoch_D_Loss:0.1276 ||Epoch_G_Loss:0.2677\n",
      "timer:  15.8202 sec.\n",
      "-------------\n",
      "Epoch 28/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 28 || Epoch_D_Loss:0.0219 ||Epoch_G_Loss:0.2991\n",
      "timer:  15.5716 sec.\n",
      "-------------\n",
      "Epoch 29/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 29 || Epoch_D_Loss:0.1763 ||Epoch_G_Loss:0.1918\n",
      "timer:  15.4958 sec.\n",
      "-------------\n",
      "Epoch 30/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 30 || Epoch_D_Loss:0.0982 ||Epoch_G_Loss:0.2676\n",
      "timer:  15.5644 sec.\n",
      "-------------\n",
      "Epoch 31/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 31 || Epoch_D_Loss:0.1029 ||Epoch_G_Loss:0.2257\n",
      "timer:  15.4895 sec.\n",
      "-------------\n",
      "Epoch 32/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 32 || Epoch_D_Loss:0.0897 ||Epoch_G_Loss:0.2786\n",
      "timer:  15.5254 sec.\n",
      "-------------\n",
      "Epoch 33/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 33 || Epoch_D_Loss:0.0421 ||Epoch_G_Loss:0.2365\n",
      "timer:  15.5199 sec.\n",
      "-------------\n",
      "Epoch 34/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 34 || Epoch_D_Loss:0.1058 ||Epoch_G_Loss:0.3452\n",
      "timer:  15.4230 sec.\n",
      "-------------\n",
      "Epoch 35/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 35 || Epoch_D_Loss:0.1072 ||Epoch_G_Loss:0.2256\n",
      "timer:  15.3734 sec.\n",
      "-------------\n",
      "Epoch 36/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 36 || Epoch_D_Loss:0.0985 ||Epoch_G_Loss:0.1933\n",
      "timer:  15.5565 sec.\n",
      "-------------\n",
      "Epoch 37/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 37 || Epoch_D_Loss:0.0913 ||Epoch_G_Loss:0.1957\n",
      "timer:  15.5274 sec.\n",
      "-------------\n",
      "Epoch 38/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 38 || Epoch_D_Loss:0.1109 ||Epoch_G_Loss:0.1991\n",
      "timer:  15.4917 sec.\n",
      "-------------\n",
      "Epoch 39/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 39 || Epoch_D_Loss:0.1171 ||Epoch_G_Loss:0.1540\n",
      "timer:  15.4744 sec.\n",
      "-------------\n",
      "Epoch 40/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 40 || Epoch_D_Loss:0.1181 ||Epoch_G_Loss:0.1563\n",
      "timer:  15.3784 sec.\n",
      "-------------\n",
      "Epoch 41/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 41 || Epoch_D_Loss:0.1004 ||Epoch_G_Loss:0.1495\n",
      "timer:  15.4433 sec.\n",
      "-------------\n",
      "Epoch 42/300\n",
      "-------------\n",
      "(train)\n",
      "-------------\n",
      "epoch 42 || Epoch_D_Loss:0.1144 ||Epoch_G_Loss:0.1658\n",
      "timer:  15.4635 sec.\n",
      "-------------\n",
      "Epoch 43/300\n",
      "-------------\n",
      "(train)\n"
     ]
    }
   ],
   "source": [
    "# 학습 및 검증을 실행한다\n",
    "# 8분 정도 걸립니다\n",
    "num_epochs = 300\n",
    "G_update, D_update = train_model(\n",
    "    G, D, dataloader=train_dataloader, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d477afd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G_update' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-838ffd85973b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfixed_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mfixed_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfixed_z\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfixed_z\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_z\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mfake_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mG_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfixed_z\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# 훈련 데이터\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'G_update' is not defined"
     ]
    }
   ],
   "source": [
    "# 생성 이미지와 훈련 데이터를 시각화한다\n",
    "# 이 셀은 몇 번을 재실행하고 있습니다.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 입력 난수 생성\n",
    "batch_size = 8\n",
    "z_dim = 20\n",
    "fixed_z = torch.randn(batch_size, z_dim)\n",
    "fixed_z = fixed_z.view(fixed_z.size(0), fixed_z.size(1), 1, 1)\n",
    "fake_images = G_update(fixed_z.to(device))\n",
    "\n",
    "# 훈련 데이터\n",
    "batch_iterator = iter(train_dataloader)  # 반복자로 변환\n",
    "imges = next(batch_iterator)  # 1번째 요소를 꺼낸다\n",
    "\n",
    "\n",
    "# 출력\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i in range(0, 5):\n",
    "    # 상단에 훈련 데이터를,\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n",
    "\n",
    "    # 하단에 생성 데이터를 표시한다\n",
    "    plt.subplot(2, 5, 5+i+1)\n",
    "    plt.imshow(fake_images[i][0].cpu().detach().numpy(), 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Anomaly_score(x, fake_img, D, Lambda=0.1):\n",
    "\n",
    "    # 테스트 화상 x와 생성 화상 fake_img의 픽셀 수준의 차이의 절대 값을 계산하여, 미니 배치마다 합을 구한다\n",
    "    residual_loss = torch.abs(x-fake_img)\n",
    "    residual_loss = residual_loss.view(residual_loss.size()[0], -1)\n",
    "    residual_loss = torch.sum(residual_loss, dim=1)\n",
    "\n",
    "    # 테스트 화상 x와 생성 화상 fake_img를 식별기 D에 입력하여, 특징량 맵을 꺼낸다\n",
    "    _, x_feature = D(x)\n",
    "    _, G_feature = D(fake_img)\n",
    "\n",
    "    # 테스트 화상 x와 생성 화상 fake_img의 특징량의 차이의 절대값을 계산하여, 미니 배치마다 합을 구한다\n",
    "    discrimination_loss = torch.abs(x_feature-G_feature)\n",
    "    discrimination_loss = discrimination_loss.view(\n",
    "        discrimination_loss.size()[0], -1)\n",
    "    discrimination_loss = torch.sum(discrimination_loss, dim=1)\n",
    "\n",
    "    # 미니 배치마다 2종류의 손실을 더한다\n",
    "    loss_each = (1-Lambda)*residual_loss + Lambda*discrimination_loss\n",
    "\n",
    "    # 미니 배치 전부의 손실을 구한다\n",
    "    total_loss = torch.sum(loss_each)\n",
    "\n",
    "    return total_loss, loss_each, residual_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd42db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용 DataLoader 작성\n",
    "def make_test_datapath_list():\n",
    "    \"\"\"학습 및 검증 화상 데이터와 어노테이션 데이터의 파일 경로 리스트를 작성한다. \"\"\"\n",
    "\n",
    "    train_img_list = list()  # 화상 파일 경로를 저장\n",
    "\n",
    "    for img_idx in range(5):\n",
    "        img_path = \"./data/test/img_7_\" + str(img_idx)+'.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "\n",
    "        img_path = \"./data/test/img_8_\" + str(img_idx)+'.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "\n",
    "        img_path = \"./data/test/img_2_\" + str(img_idx)+'.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "\n",
    "    return train_img_list\n",
    "\n",
    "\n",
    "# 파일 리스트를 작성\n",
    "test_img_list = make_test_datapath_list()\n",
    "\n",
    "# Dataset 작성\n",
    "mean = (0.5,)\n",
    "std = (0.5,)\n",
    "test_dataset = GAN_Img_Dataset(\n",
    "    file_list=test_img_list, transform=ImageTransform(mean, std))\n",
    "\n",
    "# DataLoader 작성\n",
    "batch_size = 5\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce71eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 확인\n",
    "batch_iterator = iter(test_dataloader)  # 반복자로 변환\n",
    "imges = next(batch_iterator)  \n",
    "\n",
    "# 첫번째 미니 배치를 꺼낸다\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i in range(0, 5):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f3ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이상 탐지할 화상\n",
    "x = imges[0:5]\n",
    "x = x.to(device)\n",
    "\n",
    "# 이상 탐지할 화상을 생성하기 위한 초기 난수\n",
    "z = torch.randn(5, 20).to(device)\n",
    "z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "\n",
    "# 변수 z를 미분할 수 있도록, requires_grad을 True로 설정\n",
    "z.requires_grad = True\n",
    "\n",
    "# 변수 z를 갱신할 수 있도록, z의 최적화 함수를 구한다\n",
    "z_optimizer = torch.optim.Adam([z], lr=1e-3)\n",
    "\n",
    "# z를 구한다\n",
    "for epoch in range(5000+1):\n",
    "    fake_img = G_update(z)\n",
    "    loss, _, _ = Anomaly_score(x, fake_img, D_update, Lambda=0.1)\n",
    "\n",
    "    z_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    z_optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print('epoch {} || loss_total:{:.0f} '.format(epoch, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92266cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 화상 생성\n",
    "G_update.eval()\n",
    "fake_img = G_update(z)\n",
    "\n",
    "# 손실을 구한다\n",
    "loss, loss_each, residual_loss_each = Anomaly_score(\n",
    "    x, fake_img, D_update, Lambda=0.1)\n",
    "\n",
    "# 손실 계산. 총 손실\n",
    "loss_each = loss_each.cpu().detach().numpy()\n",
    "print(\"total loss: \", np.round(loss_each, 0))\n",
    "\n",
    "# 화상을 시각화\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i in range(0, 5):\n",
    "    # 상단에 테스트 데이터를,\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n",
    "\n",
    "    # 하단에 생성 데이터를 표시한다\n",
    "    plt.subplot(2, 5, 5+i+1)\n",
    "    plt.imshow(fake_img[i][0].cpu().detach().numpy(), 'gray')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_pytorch",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
